Introduction au Deep Learning (notes
de cours)
Romain Tavenard
11 aoÃ»t 2025




TABLE DES MATIEÌ€RES
1
Introduction
3
1.1
Un premier modeÌ€le : le perceptron . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Optimisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.3
ReÌcapitulatif
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2
Perceptrons multicouches
9
2.1
Empiler des couches pour une meilleure expressiviteÌ . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
2.2
DeÌcider de lâ€™architecture dâ€™un MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.3
Fonctions dâ€™activation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.4
DeÌclarer un MLP en keras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
3
Fonctions de coÃ»t
17
3.1
Erreur quadratique moyenne . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
3.2
Perte logistique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
4
Optimisation
19
4.1
Descente de gradient stochastique
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
4.2
Une note sur Adam . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
4.3
La maleÌdiction de la profondeur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
4.4
Coder tout cela en keras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
4.5
PreÌtraitement des donneÌes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
5
RÃ©gularisation
27
5.1
Early stopping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
5.2
PeÌnalisation de la perte . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
5.3
DropOut
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
6
RÃ©seaux neuronaux convolutifs
33
6.1
ReÌseaux de neurones convolutifs pour les seÌries temporelles . . . . . . . . . . . . . . . . . . . . . . .
33
6.2
ReÌseaux de neurones convolutifs pour les images . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
7
RÃ©seaux neuronaux rÃ©currents
41
7.1
ReÌseaux reÌcurrents standard
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
7.2
Long Short Term Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
7.3
Gated Recurrent Unit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
7.4
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
i


8
MÃ©canisme dâ€™attention
47
8.1
Motivation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
8.2
Principe geÌneÌral
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
8.3
MeÌtaphore : Queries, Keys, Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
8.4
Formulation matheÌmatique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
8.5
Auto-attention (ou self-attention) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
8.6
Multi-head attention
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
8.7
ScheÌma geÌneÌral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
8.8
ReÌsumeÌ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
9
RÃ©seaux neuronaux gÃ©nÃ©ratifs
51
9.1
Auto-encodeurs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
9.2
Variational Auto-Encoders (VAE) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
9.3
Generative Adversarial Networks (GAN) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
9.4
ModeÌ€les de diffusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
9.5
Conditional Flow Matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
9.6
ReÌsumeÌ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
Bibliographie
55
ii


Introduction au Deep Learning (notes de cours)
par Romain Tavenard
Ce document sert de notes de cours pour un cours dispenseÌ aÌ€ lâ€™UniversiteÌ de Rennes 2 (France) et aÌ€ lâ€™EDHEC Lille
(France).
Le cours traite des bases des reÌseaux de neurones pour la classification et la reÌgression sur des donneÌes tabulaires (y
compris les algorithmes dâ€™optimisation pour les perceptrons multicouches), les reÌseaux de neurones convolutifs pour la
classification dâ€™images (y compris les notions dâ€™apprentissage par transfert) et la classification / preÌvision de seÌquences.
Les seÌances de travaux pratiques de ce cours utiliseront keras, tout comme ces notes de cours.
NB : ces notes ont Ã©tÃ© traduites vers le franÃ§ais de maniÃ¨re semi-automatique, nâ€™hÃ©sitez pas Ã  vous rÃ©fÃ©rer Ã  la version
anglaise en cas de doute.
TABLE DES MATIÃˆRES
1


Introduction au Deep Learning (notes de cours)
2
TABLE DES MATIÃˆRES


CHAPITRE 1
INTRODUCTION
Dans ce chapitre dâ€™introduction, nous allons preÌsenter un premier reÌseau neuronal appeleÌ le Perceptron. Ce modeÌ€le est un
reÌseau neuronal constitueÌ dâ€™un seul neurone, et nous lâ€™utiliserons ici pour introduire des concepts-cleÌs que nous deÌtaillerons
plus tard dans le cours.
1.1 Un premier modÃ¨le : le perceptron
Dans la terminologie des reÌseaux de neurones, un neurone est une fonction parameÌtreÌe qui prend un vecteur x en entreÌe
et sort une valeur unique ğ‘comme suit :
ğ‘= ğœ‘(wx + ğ‘
âŸ
ğ‘œ
),
ouÌ€ les parameÌ€tres du neurone sont ses poids stockeÌs dans w. et un terme de biais ğ‘, et ğœ‘est une fonction dâ€™activation qui
est choisie a priori (nous y reviendrons plus en deÌtail plus tard dans le cours) :
ğ‘œ
ğ‘
ğ‘¥0
ğ‘¥1
ğ‘¥2
ğ‘¥3
+1
ğ‘¤0
ğ‘¤1
ğ‘¤2
ğ‘¤3
ğ‘
ğœ‘
Un modeÌ€le constitueÌ dâ€™un seul neurone est appeleÌ perceptron.
3


Introduction au Deep Learning (notes de cours)
1.2 Optimisation
Les modeÌ€les preÌsenteÌs dans ce document ont pour but de reÌsoudre des probleÌ€mes de preÌdiction dans lesquels lâ€™objectif est
de trouver des valeurs de parameÌ€tres Â« suffisamment bonnes Â» pour le modeÌ€le en jeu compte tenu de donneÌes observeÌes.
Le probleÌ€me de la recherche de telles valeurs de parameÌ€tres est appeleÌ optimisation. Lâ€™apprentissage profond (ou deep
learning) fait un usage intensif dâ€™une famille speÌcifique de strateÌgies dâ€™optimisation appeleÌe descente gradiente.
1.2.1 Descente de gradient
Pour se faire une ideÌe de la descente de gradient, supposons que lâ€™on nous donne le jeu de donneÌes suivant sur les prix de
lâ€™immobilier :
import pandas as pd
boston = pd.read_csv("../data/boston.csv")[["RM", "PRICE"]]
boston
RM
PRICE
0
6.575
24.0
1
6.421
21.6
2
7.185
34.7
3
6.998
33.4
4
7.147
36.2
..
...
...
501
6.593
22.4
502
6.120
20.6
503
6.976
23.9
504
6.794
22.0
505
6.030
11.9
[506 rows x 2 columns]
Dans notre cas, nous essaierons (pour commencer) de preÌdire la valeur cible "PRICE" de ce jeu de donneÌes, qui est la
valeur meÌdiane des maisons occupeÌes par leur proprieÌtaire en milliers de dollars en fonction du nombre moyen de pieÌ€ces
par logement "RM" :
sns.scatterplot(data=boston, x="RM", y="PRICE");
4
Chapitre 1. Introduction


Introduction au Deep Learning (notes de cours)
Une courte note sur ce modÃ¨le
Dans la terminologie du Perceptron, ce modeÌ€le :
â€” nâ€™a pas de fonction dâ€™activation (i.e. ğœ‘est la fonction dâ€™identiteÌ)
â€” nâ€™a pas de biais (i.e. ğ‘est fixeÌ aÌ€ 0, il nâ€™est pas appris)
Supposons que nous ayons une approche naÃ¯ve dans laquelle notre modeÌ€le de preÌdiction est lineÌaire sans biais, câ€™est-aÌ€-dire
que pour une entreÌe donneÌe ğ‘¥ğ‘–la sortie preÌdite est calculeÌe comme suit :
Ì‚ğ‘¦ğ‘–= ğ‘¤ğ‘¥ğ‘–
ouÌ€ ğ‘¤est le seul parameÌ€tre de notre modeÌ€le.
Supposons en outre que la quantiteÌ que nous cherchons aÌ€ minimiser (notre objectif, eÌgalement appeleÌ fonction de perte)
est :
â„’(ğ‘¤) = âˆ‘
ğ‘–
( Ì‚ğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–)
2
ouÌ€ ğ‘¦ğ‘–est la valeur cible associeÌe au ğ‘–-eÌ€me eÌchantillon de jeu de donneÌes.
Examinons cette quantiteÌ en fonction de ğ‘¤:
import numpy as np
def loss(w, x, y):
w = np.array(w)
return np.sum(
(w[:, None] * x.to_numpy()[None, :] - y.to_numpy()[None, :]) ** 2,
axis=1
)
w = np.linspace(-2, 10, num=100)
x = boston["RM"]
y = boston["PRICE"]
plt.plot(w, loss(w, x, y), "r-");
1.2. Optimisation
5


Introduction au Deep Learning (notes de cours)
Ici, il semble quâ€™une valeur de ğ‘¤autour de 4 devrait eÌ‚tre un bon choix. Cette meÌthode (geÌneÌrer de nombreuses valeurs pour
le parameÌ€tre et calculer la perte pour chaque valeur) ne peut pas sâ€™adapter aux modeÌ€les qui ont beaucoup de parameÌ€tres,
donc nous allons donc essayer autre chose.
Supposons que nous ayons acceÌ€s, aÌ€ chaque fois que nous choisissons une valeur candidate pour ğ‘¤, aÌ€ la fois aÌ€ la perte
â„’et aux informations sur la faÃ§on dont â„’varie, localement. Nous pourrions, dans ce cas, calculer une nouvelle valeur
candidate pour ğ‘¤en nous deÌplaÃ§ant aÌ€ partir de la valeur candidate preÌceÌdente dans la direction de la descente la plus raide.
Câ€™est lâ€™ideÌe de base de lâ€™algorithme de descente du gradient qui, aÌ€ partir dâ€™un candidat initial ğ‘¤0, calcule iteÌrativement de
nouveaux candidats comme :
ğ‘¤ğ‘¡+1 = ğ‘¤ğ‘¡âˆ’ğœŒğœ•â„’
ğœ•ğ‘¤âˆ£
ğ‘¤=ğ‘¤ğ‘¡
ouÌ€ ğœŒest un hyper-parameÌ€tre (appeleÌ taux dâ€™apprentissage) qui controÌ‚le la taille des pas aÌ€ effectuer, et ğœ•â„’
ğœ•ğ‘¤âˆ£ğ‘¤=ğ‘¤ğ‘¡est le
gradient de â„’par rapport aÌ€ ğ‘¤, eÌvalueÌ en ğ‘¤= ğ‘¤ğ‘¡. Comme vous pouvez le voir, la direction de la descente la plus raide
est lâ€™opposeÌ de la direction indiqueÌe par le gradient (et cela vaut aussi pour les parameÌ€tres vectoriels).
Ce processus est reÌpeÌteÌ jusquâ€™aÌ€ la convergence, comme lâ€™illustre la figure suivante :
rho = 1e-5
def grad_loss(w_t, x, y):
return np.sum(
2 * (w_t * x - y) * x
)
ww = np.linspace(-2, 10, num=100)
plt.plot(ww, loss(ww, x, y), "r-", alpha=.5);
w = [0.]
for t in range(10):
w_update = w[t] - rho * grad_loss(w[t], x, y)
w.append(w_update)
plt.plot(w, loss(w, x, y), "ko-")
plt.text(x=w[0]+.1, y=loss([w[0]], x, y), s="$w_{0}$")
plt.text(x=w[10]+.1, y=loss([w[10]], x, y), s="$w_{10}$");
6
Chapitre 1. Introduction


Introduction au Deep Learning (notes de cours)
Quâ€™obtiendrions-nous si nous utilisions un taux dâ€™apprentissage plus faible?
rho = 1e-6
ww = np.linspace(-2, 10, num=100)
plt.plot(ww, loss(ww, x, y), "r-", alpha=.5);
w = [0.]
for t in range(10):
w_update = w[t] - rho * grad_loss(w[t], x, y)
w.append(w_update)
plt.plot(w, loss(w, x, y), "ko-")
plt.text(x=w[0]+.1, y=loss([w[0]], x, y), s="$w_{0}$")
plt.text(x=w[10]+.1, y=loss([w[10]], x, y), s="$w_{10}$");
Cela prendrait certainement plus de temps pour converger. Mais attention, un taux dâ€™apprentissage plus eÌleveÌ nâ€™est pas
toujours une bonne ideÌe :
1.2. Optimisation
7


Introduction au Deep Learning (notes de cours)
rho = 5e-5
ww = np.linspace(-2, 10, num=100)
plt.plot(ww, loss(ww, x, y), "r-", alpha=.5);
w = [0.]
for t in range(10):
w_update = w[t] - rho * grad_loss(w[t], x, y)
w.append(w_update)
plt.plot(w, loss(w, x, y), "ko-")
plt.text(x=w[0]-1., y=loss([w[0]], x, y), s="$w_{0}$")
plt.text(x=w[10]-1., y=loss([w[10]], x, y), s="$w_{10}$");
Vous voyez comment nous divergeons lentement parce que nos pas sont trop grands?
1.3 RÃ©capitulatif
Dans cette section, nous avons introduit :
â€” un modeÌ€le treÌ€s simple, appeleÌ le Perceptron : ce sera une brique de base pour les modeÌ€les plus avanceÌs que nous
deÌtaillerons plus tard dans le cours, tels que :
â€” le Perceptron multi-couches
â€” les architectures convolutionnelles
â€” les architectures rÃ©currentes
â€” les architectures basÃ©es attention
â€” le fait quâ€™une taÌ‚che sâ€™accompagne dâ€™une fonction de perte aÌ€ minimiser (ici, nous avons utiliseÌ lâ€™erreur quadratique
moyenne pour notre taÌ‚che de reÌgression), qui sera discuteÌe dans un chapitre dÃ©diÃ© ;
â€” le concept de descente de gradient pour optimiser la perte choisie sur le parameÌ€tre unique dâ€™un modeÌ€le, et ceci
sera eÌtendu dans notre chapitre sur lâ€™optimisation.
8
Chapitre 1. Introduction


CHAPITRE 2
PERCEPTRONS MULTICOUCHES
Dans le chapitre preÌceÌdent, nous avons vu un modeÌ€le treÌ€s simple appeleÌ le perceptron. Dans ce modeÌ€le, la sortie preÌdite
Ì‚ğ‘¦est calculeÌe comme une combinaison lineÌaire des caracteÌristiques dâ€™entreÌe plus un biais :
Ì‚ğ‘¦=
ğ‘‘
âˆ‘
ğ‘—=1
ğ‘¥ğ‘—ğ‘¤ğ‘—+ ğ‘
En dâ€™autres termes, nous optimisions parmi la famille des modeÌ€les lineÌaires, qui est une famille assez restreinte.
2.1 Empiler des couches pour une meilleure expressivitÃ©
Afin de couvrir un plus large eÌventail de modeÌ€les, on peut empiler des neurones organiseÌs en couches pour former un
modeÌ€le plus complexe, comme le modeÌ€le ci-dessous, qui est appeleÌ modeÌ€le aÌ€ une couche cacheÌe, car une couche suppleÌ-
mentaire de neurones est introduite entre les entreÌes et la sortie :
Couche d'entreÌe
x
Couche cacheÌe
h(1)
Couche de sortie
Ì‚y
w(0)
w(1)
9


Introduction au Deep Learning (notes de cours)
La question que lâ€™on peut se poser maintenant est de savoir si cette couche cacheÌe suppleÌmentaire permet effectivement
de couvrir une plus grande famille de modeÌ€les. Câ€™est aÌ€ cela que sert le theÌoreÌ€me dâ€™approximation universelle ci-dessous.
Â® ThÃ©orÃ¨me dâ€™approximation universelle
Le theÌoreÌ€me dâ€™approximation universelle stipule que toute fonction continue deÌfinie sur un ensemble compact peut
eÌ‚tre approcheÌe dâ€™aussi preÌ€s que lâ€™on veut par un reÌseau neuronal aÌ€ une couche cacheÌe avec activation sigmoÃ¯de.
En dâ€™autres termes, en utilisant une couche cacheÌe pour mettre en correspondance les entreÌes et les sorties, on peut
maintenant approximer nâ€™importe quelle fonction continue, ce qui est une proprieÌteÌ treÌ€s inteÌressante. Notez cependant
que le nombre de neurones cacheÌs neÌcessaire pour obtenir une qualiteÌ dâ€™approximation donneÌe nâ€™est pas discuteÌ ici. De
plus, il nâ€™est pas suffisant quâ€™une telle bonne approximation existe, une autre question importante est de savoir si les
algorithmes dâ€™optimisation que nous utiliserons convergeront in fine vers cette solution ou non, ce qui nâ€™est pas garanti,
comme discuteÌ plus en deÌtail dans le chapitre dÃ©diÃ©.
En pratique, nous observons empiriquement que pour atteindre une qualiteÌ dâ€™approximation donneÌe, il est plus efficace
(en termes de nombre de parameÌ€tres requis) dâ€™empiler plusieurs couches cacheÌes plutoÌ‚t que de sâ€™appuyer sur une seule :
Couche d'entreÌe
x
PremieÌ€re
couche cacheÌe
h(1)
Seconde
couche cacheÌe
h(2)
Couche de sortie
Ì‚y
w(0)
w(1)
w(2)
La repreÌsentation graphique ci-dessus correspond au modeÌ€le suivant :
Ì‚ğ‘¦= ğœ‘out (âˆ‘
ğ‘–
ğ‘¤(2)
ğ‘–â„(2)
ğ‘–
+ ğ‘(2))
(2.1)
âˆ€ğ‘–, â„(2)
ğ‘–
= ğœ‘(âˆ‘
ğ‘—
ğ‘¤(1)
ğ‘–ğ‘—â„(1)
ğ‘—
+ ğ‘(1)
ğ‘–)
(2.2)
âˆ€ğ‘–, â„(1)
ğ‘–
= ğœ‘(âˆ‘
ğ‘—
ğ‘¤(0)
ğ‘–ğ‘—ğ‘¥ğ‘—+ ğ‘(0)
ğ‘–)
(2.3)
Pour eÌ‚tre preÌcis, les termes de biais ğ‘(ğ‘™)
ğ‘–
ne sont pas repreÌsenteÌs dans la repreÌsentation graphique ci-dessus.
De tels modeÌ€les avec une ou plusieurs couches cacheÌes sont appeleÌs Perceptrons multicouches (ou Multi-Layer Percep-
trons, MLP).
10
Chapitre 2. Perceptrons multicouches


Introduction au Deep Learning (notes de cours)
2.2 DÃ©cider de lâ€™architecture dâ€™un MLP
Lors de la conception dâ€™un modeÌ€le de perceptron multicouche destineÌ aÌ€ eÌ‚tre utiliseÌ pour un probleÌ€me speÌcifique, certaines
quantiteÌs sont fixeÌes par le probleÌ€me en question et dâ€™autres sont des hyper-parameÌ€tres du modeÌ€le.
Prenons lâ€™exemple du ceÌleÌ€bre jeu de donneÌes de classification dâ€™iris :
import pandas as pd
iris = pd.read_csv("../data/iris.csv", index_col=0)
iris
sepal length (cm)
sepal width (cm)
petal length (cm)
petal width (cm)
\
0
5.1
3.5
1.4
0.2
1
4.9
3.0
1.4
0.2
2
4.7
3.2
1.3
0.2
3
4.6
3.1
1.5
0.2
4
5.0
3.6
1.4
0.2
..
...
...
...
...
145
6.7
3.0
5.2
2.3
146
6.3
2.5
5.0
1.9
147
6.5
3.0
5.2
2.0
148
6.2
3.4
5.4
2.3
149
5.9
3.0
5.1
1.8
target
0
0
1
0
2
0
3
0
4
0
..
...
145
2
146
2
147
2
148
2
149
2
[150 rows x 5 columns]
Lâ€™objectif ici est dâ€™apprendre aÌ€ deÌduire lâ€™attribut Â« cible Â» (3 classes diffeÌrentes possibles) aÌ€ partir des informations conte-
nues dans les 4 autres attributs.
La structure de ce jeu de donneÌes dicte :
â€” le nombre de neurones dans la couche dâ€™entreÌe, qui est eÌgal au nombre dâ€™attributs descriptifs dans notre jeu de
donneÌes (ici, 4), et
â€” le nombre de neurones dans la couche de sortie, qui est ici eÌgal aÌ€ 3, puisque le modeÌ€le est censeÌ produire une
probabiliteÌ par classe cible.
De manieÌ€re plus geÌneÌrale, pour la couche de sortie, on peut eÌ‚tre confronteÌ aÌ€ plusieurs situations :
â€” lorsquâ€™il sâ€™agit de reÌgression, le nombre de neurones de la couche de sortie est eÌgal au nombre de caracteÌristiques
aÌ€ preÌdire par le modeÌ€le,
â€” quand il sâ€™agit de classification
â€” Dans le cas dâ€™une classification binaire, le modeÌ€le aura un seul neurone de sortie qui indiquera la probabiliteÌ
de la classe positive,
2.2. DÃ©cider de lâ€™architecture dâ€™un MLP
11


Introduction au Deep Learning (notes de cours)
â€” dans le cas dâ€™une classification multi-classes, le modeÌ€le aura autant de neurones de sortie que le nombre de
classes du probleÌ€me.
Une fois que ces nombres de neurones dâ€™entreÌe / sortie sont fixeÌs, le nombre de neurones cacheÌs ainsi que le nombre de
neurones par couche cacheÌe restent des hyper-parameÌ€tres du modeÌ€le.
2.3 Fonctions dâ€™activation
Un autre hyper-parameÌ€tre important des reÌseaux neuronaux est le choix de la fonction dâ€™activation ğœ‘.
Il est important de noter que si nous utilisons la fonction identiteÌ comme fonction dâ€™activation, quelle que soit la profondeur
de notre MLP, nous ne couvrirons plus que la famille des modeÌ€les lineÌaires. En pratique, nous utiliserons donc des
fonctions dâ€™activation qui ont un certain reÌgime lineÌaire mais qui ne se comportent pas comme une fonction lineÌaire sur
toute la gamme des valeurs dâ€™entreÌe.
Historiquement, les fonctions dâ€™activation suivantes ont eÌteÌ proposeÌes :
tanh(ğ‘¥) =
2
1 + ğ‘’âˆ’2ğ‘¥âˆ’1
sigmoid(ğ‘¥) =
1
1 + ğ‘’âˆ’ğ‘¥
ReLU(ğ‘¥) = {ğ‘¥si ğ‘¥> 0
0 sinon
En pratique, la fonction ReLU (et certaines de ses variantes) est la plus utiliseÌe de nos jours, pour des raisons qui seront
discuteÌes plus en deÌtail dans notre chapitre consacrÃ© Ã  lâ€™optimisation.
2.3.1 Le cas particulier de la couche de sortie
Vous avez peut-eÌ‚tre remarqueÌ que dans la formulation du MLP fournie par lâ€™eÌquation (1), la couche de sortie posseÌ€de sa
propre fonction dâ€™activation, noteÌe ğœ‘out. Cela sâ€™explique par le fait que le choix de la fonction dâ€™activation pour la couche
de sortie dâ€™un reÌseau neuronal est speÌcifique au probleÌ€me aÌ€ reÌsoudre.
En effet, vous avez pu constater que les fonctions dâ€™activation abordeÌes dans la section preÌceÌdente ne partagent pas la
meÌ‚me plage de valeurs de sortie. Il est donc primordial de choisir une fonction dâ€™activation adeÌquate pour la couche de
sortie, de sorte que notre modeÌ€le produise des valeurs coheÌrentes avec les quantiteÌs quâ€™il est censeÌ preÌdire.
Si, par exemple, notre modeÌ€le est censeÌ eÌ‚tre utiliseÌ dans lâ€™ensemble de donneÌes sur les logements de Boston dont nous
avons parleÌ dans le chapitre prÃ©cÃ©dent, lâ€™objectif est de preÌdire les prix des logements, qui sont censeÌs eÌ‚tre des quantiteÌs non
12
Chapitre 2. Perceptrons multicouches


Introduction au Deep Learning (notes de cours)
neÌgatives. Il serait donc judicieux dâ€™utiliser ReLU (qui peut produire toute valeur positive) comme fonction dâ€™activation
pour la couche de sortie dans ce cas.
Comme indiqueÌ preÌceÌdemment, dans le cas de la classification binaire, le modeÌ€le aura un seul neurone de sortie et ce
neurone produira la probabiliteÌ associeÌe aÌ€ la classe positive. Cette quantiteÌ devra se situer dans lâ€™intervalle [0, 1], et la
fonction dâ€™activation sigmoÃ¯de est alors le choix par deÌfaut dans ce cas.
Enfin, lorsque la classification multi-classes est en jeu, nous avons un neurone par classe de sortie et chaque neurone est
censeÌ fournir la probabiliteÌ pour une classe donneÌe. Dans ce contexte, les valeurs de sortie doivent eÌ‚tre comprises entre
0 et 1, et leur somme doit eÌ‚tre eÌgale aÌ€ 1. AÌ€ cette fin, nous utilisons la fonction dâ€™activation softmax deÌfinie comme suit :
âˆ€ğ‘–, softmax(ğ‘œğ‘–) =
ğ‘’ğ‘œğ‘–
âˆ‘ğ‘—ğ‘’ğ‘œğ‘—
ouÌ€, pour tous les ğ‘–, les ğ‘œğ‘–sont les valeurs des neurones de sortie avant application de la fonction dâ€™activation.
2.4 DÃ©clarer un MLP en keras
Pour deÌfinir un modeÌ€le MLP dans keras, il suffit dâ€™empiler des couches. A titre dâ€™exemple, si lâ€™on veut coder un modeÌ€le
composeÌ de :
â€” une couche dâ€™entreÌe avec 10 neurones,
â€” dâ€™une couche cacheÌe de 20 neurones avec activation ReLU,
â€” une couche de sortie composeÌe de 3 neurones avec activation softmax,
le code sera le suivant :
import keras
from keras.layers import Dense, InputLayer
from keras.models import Sequential
model = Sequential([
InputLayer(input_shape=(10, )),
Dense(units=20, activation="relu"),
Dense(units=3, activation="softmax")
])
model.summary()
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒLayer (type)
â”ƒOutput Shape
â”ƒ
Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚dense (Dense)
â”‚(None, 20)
â”‚
220 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚dense_1 (Dense)
â”‚(None, 3)
â”‚
63 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total params: 283 (1.11 KB)
Trainable params: 283 (1.11 KB)
2.4. DÃ©clarer un MLP en keras
13


Introduction au Deep Learning (notes de cours)
Non-trainable params: 0 (0.00 B)
Notez que model.summary() fournit un aperÃ§u inteÌressant dâ€™un modeÌ€le deÌfini et de ses parameÌ€tres.
Â® Exercice #1
En vous basant sur ce que nous avons vu dans ce chapitre, pouvez-vous expliquer le nombre de parameÌ€tres retourneÌs
par model.summary() ci-dessus?
Â® Solution
Notre couche dâ€™entreÌe est composeÌe de 10 neurones, et notre premieÌ€re couche est entieÌ€rement connecteÌe, donc
chacun de ces neurones est connecteÌ aÌ€ un neurone de la couche cacheÌe par un parameÌ€tre, ce qui fait deÌjaÌ€ 10Ã—20 =
200 parameÌ€tres. De plus, chacun des neurones de la couche cacheÌe posseÌ€de son propre parameÌ€tre de biais, ce qui
fait 20 parameÌ€tres suppleÌmentaires. Nous avons donc 220 parameÌ€tres, tels que sortis par model.summary()
pour la couche "dense (Dense)".
De la meÌ‚me manieÌ€re, pour la connexion des neurones de la couche cacheÌe aÌ€ ceux de la couche de sortie, le nombre
total de parameÌ€tres est de 20 Ã— 3 = 60 pour les poids plus 3 parameÌ€tres suppleÌmentaires pour les biais.
Au total, nous avons 220 + 63 = 283 parameÌ€tres dans ce modeÌ€le.
Â® Exercice #2
DeÌclarez, en keras, un MLP avec une couche cacheÌe composeÌe de 100 neurones et une activation ReLU pour le
jeu de donneÌes Iris preÌsenteÌ ci-dessus.
Â® Solution
model = Sequential([
InputLayer(input_shape=(4, )),
Dense(units=100, activation="relu"),
Dense(units=3, activation="softmax")
])
Â® Exercice #3
MeÌ‚me question pour le jeu de donneÌes sur le logement aÌ€ Boston preÌsenteÌ ci-dessous (le but ici est de preÌdire lâ€™attribut
PRICE en fonction des autres).
Â® Solution
model = Sequential([
InputLayer(input_shape=(6, )),
Dense(units=100, activation="relu"),
Dense(units=1, activation="relu")
])
14
Chapitre 2. Perceptrons multicouches


Introduction au Deep Learning (notes de cours)
RM
CRIM
INDUS
NOX
AGE
TAX
PRICE
0
6.575
0.00632
2.31
0.538
65.2
296.0
24.0
1
6.421
0.02731
7.07
0.469
78.9
242.0
21.6
2
7.185
0.02729
7.07
0.469
61.1
242.0
34.7
3
6.998
0.03237
2.18
0.458
45.8
222.0
33.4
4
7.147
0.06905
2.18
0.458
54.2
222.0
36.2
..
...
...
...
...
...
...
...
501
6.593
0.06263
11.93
0.573
69.1
273.0
22.4
502
6.120
0.04527
11.93
0.573
76.7
273.0
20.6
503
6.976
0.06076
11.93
0.573
91.0
273.0
23.9
504
6.794
0.10959
11.93
0.573
89.3
273.0
22.0
505
6.030
0.04741
11.93
0.573
80.8
273.0
11.9
[506 rows x 7 columns]
2.4. DÃ©clarer un MLP en keras
15


Introduction au Deep Learning (notes de cours)
16
Chapitre 2. Perceptrons multicouches


CHAPITRE 3
FONCTIONS DE COUÌ‚ T
Nous avons maintenant preÌsenteÌ une premieÌ€re famille de modeÌ€les, qui est la famille MLP. Afin dâ€™entraÃ®ner ces modeÌ€les
(i.e. dâ€™ajuster leurs parameÌ€tres pour quâ€™ils sâ€™adaptent aux donneÌes), nous devons deÌfinir une fonction de couÌ‚t (aussi appeleÌe
fonction de perte, ou loss function) aÌ€ optimiser. Une fois cette fonction choisie, lâ€™optimisation consistera aÌ€ reÌgler les
parameÌ€tres du modeÌ€le de manieÌ€re aÌ€ la minimiser.
Dans cette section, nous preÌsenterons deux fonctions de pertes standard, aÌ€ savoir lâ€™erreur quadratique moyenne (princi-
palement utiliseÌe pour la reÌgression) et la fonction de perte logistique (utiliseÌe en classification).
Dans ce qui suit, nous supposons connu un ensemble de donneÌes ğ’ŸcomposeÌ de ğ‘›eÌchantillons annoteÌs (ğ‘¥ğ‘–, ğ‘¦ğ‘–), et nous
deÌsignons la sortie du modeÌ€le :
âˆ€ğ‘–, Ì‚ğ‘¦ğ‘–= ğ‘šğœƒ(ğ‘¥ğ‘–)
ouÌ€ ğ‘šğœƒest notre modeÌ€le et ğœƒest lâ€™ensemble de tous ses parameÌ€tres (poids et biais).
3.1 Erreur quadratique moyenne
Lâ€™erreur quadratique moyenne (ou Mean Squared Error, MSE) est la fonction de perte la plus couramment utiliseÌe dans
les contextes de reÌgression. Elle est deÌfinie comme suit
â„’(ğ’Ÿ; ğ‘šğœƒ) = 1
ğ‘›âˆ‘
ğ‘–
â€– Ì‚ğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–â€–2
= 1
ğ‘›âˆ‘
ğ‘–
â€–ğ‘šğœƒ(ğ‘¥ğ‘–) âˆ’ğ‘¦ğ‘–â€–2
Sa forme quadratique tend aÌ€ peÌnaliser fortement les erreurs importantes :
17


Introduction au Deep Learning (notes de cours)
3.2 Perte logistique
La perte logistique est la fonction de perte la plus largement utiliseÌe pour entraÃ®ner des reÌseaux neuronaux dans des
contextes de classification. Elle est deÌfinie comme suit
â„’(ğ’Ÿ; ğ‘šğœƒ) = 1
ğ‘›âˆ‘
ğ‘–
âˆ’log ğ‘( Ì‚ğ‘¦ğ‘–= ğ‘¦ğ‘–; ğ‘šğœƒ)
ouÌ€ ğ‘( Ì‚ğ‘¦ğ‘–= ğ‘¦ğ‘–; ğ‘šğœƒ) est la probabiliteÌ preÌdite par le modeÌ€le ğ‘šğœƒpour la classe correcte ğ‘¦ğ‘–.
Sa formulation tend aÌ€ favoriser les cas ouÌ€ le modeÌ€le preÌdit la classe correcte avec une probabiliteÌ proche de 1, comme on
peut sâ€™y attendre :
18
Chapitre 3. Fonctions de coÃ»t


CHAPITRE 4
OPTIMISATION
Dans ce chapitre, nous preÌsenterons des variantes de la strateÌgie dâ€™optimisation de descente de gradient et montrerons
comment elles peuvent eÌ‚tre utiliseÌes pour optimiser les parameÌ€tres des reÌseaux de neurones.
CommenÃ§ons par lâ€™algorithme de base de la descente de gradient et ses limites.
Â® Algorithm 1 (Descente de Gradient)
EntrÃ©e: Un jeu de donneÌes ğ’Ÿ= (ğ‘‹, ğ‘¦)
1. Initialiser les parameÌ€tres ğœƒdu modeÌ€le
2. for ğ‘’= 1..ğ¸
1. for (ğ‘¥ğ‘–, ğ‘¦ğ‘–) âˆˆğ’Ÿ
1. Calculer la preÌdiction
Ì‚ğ‘¦ğ‘–= ğ‘šğœƒ(ğ‘¥ğ‘–)
2. Calculer le gradient individuel âˆ‡ğœƒâ„’ğ‘–
2. Calculer le gradient total âˆ‡ğœƒâ„’= 1
ğ‘›âˆ‘ğ‘–âˆ‡ğœƒâ„’ğ‘–
3. Mettre aÌ€ jour les parameÌ€tres ğœƒaÌ€ partir de âˆ‡ğœƒâ„’
La reÌ€gle de mise aÌ€ jour typique pour les parameÌ€tres ğœƒaÌ€ lâ€™iteÌration ğ‘¡est
ğœƒ(ğ‘¡+1) â†ğœƒ(ğ‘¡) âˆ’ğœŒâˆ‡ğœƒâ„’
ouÌ€ ğœŒest un hyper-parameÌ€tre important de la meÌthode, appeleÌ le taux dâ€™apprentissage (ou learning rate). La descente de
gradient consiste aÌ€ jour iteÌrativement ğœƒdans la direction de la plus forte diminution de la perte â„’.
Comme on peut le voir dans lâ€™algorithme preÌceÌdent, lors dâ€™un descente de gradient, les parameÌ€tres du modeÌ€le sont mis
aÌ€ jour une fois par epoch, ce qui signifie quâ€™un passage complet sur lâ€™ensemble des donneÌes est neÌcessaire avant la mise
aÌ€ jour. Lorsque lâ€™on traite de grands jeux de donneÌes, cela constitue une forte limitation, ce qui motive lâ€™utilisation de
variantes stochastiques.
19


Introduction au Deep Learning (notes de cours)
4.1 Descente de gradient stochastique
Lâ€™ideÌe derrieÌ€re lâ€™algorithme de descente de gradient stochastique (ou Stochastic Gradient Descent, SGD) est dâ€™obtenir des
estimations bon marcheÌ (au sens de la quantiteÌ de calculs neÌcessaires) pour la quantiteÌ
âˆ‡ğœƒâ„’(ğ’Ÿ; ğ‘šğœƒ) = 1
ğ‘›
âˆ‘
(ğ‘¥ğ‘–,ğ‘¦ğ‘–)âˆˆğ’Ÿ
âˆ‡ğœƒâ„’(ğ‘¥ğ‘–, ğ‘¦ğ‘–; ğ‘šğœƒ)
ouÌ€ ğ’Ÿest lâ€™ensemble dâ€™apprentissage. Pour ce faire, on tire des sous-ensembles de donneÌes, appeleÌs minibatchs, et
âˆ‡ğœƒâ„’(â„¬; ğ‘šğœƒ) = 1
ğ‘
âˆ‘
(ğ‘¥ğ‘–,ğ‘¦ğ‘–)âˆˆâ„¬
âˆ‡ğœƒâ„’(ğ‘¥ğ‘–, ğ‘¦ğ‘–; ğ‘šğœƒ)
est utiliseÌ comme estimateur de âˆ‡ğœƒâ„’(ğ’Ÿ; ğ‘šğœƒ). Il en reÌsulte lâ€™algorithme suivant dans lequel les mises aÌ€ jour des parameÌ€tres
se produisent apreÌ€s chaque minibatch, câ€™est-aÌ€-dire plusieurs fois par epoch.
Â® Algorithm 2 (Descente de gradient stochastique)
Input: A dataset ğ’Ÿ= (ğ‘‹, ğ‘¦)
1. Initialiser les parameÌ€tres ğœƒdu modeÌ€le
2. for ğ‘’= 1..ğ¸
1. for ğ‘¡= 1..ğ‘›minibatches
1. Tirer un eÌchantillon aleÌatoire de taillle ğ‘dans ğ’Ÿque lâ€™on appelle minibatch
2. for (ğ‘¥ğ‘–, ğ‘¦ğ‘–) âˆˆâ„¬
1. Calculer la preÌdiction
Ì‚ğ‘¦ğ‘–= ğ‘šğœƒ(ğ‘¥ğ‘–)
2. Calculer le gradient individuel âˆ‡ğœƒâ„’ğ‘–
3. Calculer le gradient sommeÌ sur le minibatch âˆ‡ğœƒâ„’â„¬= 1
ğ‘âˆ‘ğ‘–âˆ‡ğœƒâ„’ğ‘–
4. Mettre aÌ€ jour les parameÌ€tres ğœƒaÌ€ partir de âˆ‡ğœƒâ„’â„¬
Par conseÌquent, lors de lâ€™utilisation de SGD, les mises aÌ€ jour des parameÌ€tres sont plus freÌquentes, mais elles sont Â« brui-
teÌes Â» puisquâ€™elles sont baseÌes sur une estimation du gradient par minibatch au lieu de sâ€™appuyer sur le vrai gradient,
comme illustreÌ ci-dessous :
20
Chapitre 4. Optimisation


Introduction au Deep Learning (notes de cours)
Outre le fait quâ€™elle implique des mises aÌ€ jour plus freÌquentes des parameÌ€tres, la SGD preÌsente un avantage suppleÌmentaire
en termes dâ€™optimisation, qui est essentiel pour les reÌseaux de neurones. En effet, comme on peut le voir ci-dessous,
contrairement aÌ€ ce que nous avions dans le cas du Perceptron, la perte MSE (et il en va de meÌ‚me pour la perte logistique)
nâ€™est plus convexe en les parameÌ€tres du modeÌ€le deÌ€s que celui-ci posseÌ€de au moins une couche cacheÌe :
La descente de gradient est connue pour souffrir dâ€™optima locaux, et de tels fonctions de pertes constituent un probleÌ€me
seÌrieux pour la descente de gradient. Dâ€™un autre coÌ‚teÌ, la descente de gradient stochastique est susceptible de beÌneÌficier
dâ€™estimations de gradient bruiteÌes pour sâ€™eÌchapper des minima locaux.
4.1. Descente de gradient stochastique
21


Introduction au Deep Learning (notes de cours)
4.2 Une note sur Adam
Adam [Kingma and Ba, 2015] est une variante de la meÌthode de descente de gradient stochastique. Elle diffeÌ€re dans la
reÌ€gle de mise aÌ€ jour des parameÌ€tres.
Tout dâ€™abord, elle utilise ce quâ€™on appelle le momentum, qui consiste essentiellement aÌ€ sâ€™appuyer sur les mises aÌ€ jour
anteÌrieures du gradient pour lisser la trajectoire dans lâ€™espace des parameÌ€tres pendant lâ€™optimisation. Une illustration
interactive du momentum peut eÌ‚tre trouveÌe dans [Goh, 2017].
Lâ€™estimation du gradient est remplaceÌe par la quantiteÌ :
m(ğ‘¡+1) â†
1
1 âˆ’ğ›½ğ‘¡
1
[ğ›½1m(ğ‘¡) + (1 âˆ’ğ›½1)âˆ‡ğœƒâ„’]
Lorsque ğ›½1 est eÌgal aÌ€ zeÌro, nous avons m(ğ‘¡+1) = âˆ‡ğœƒâ„’et pour ğ›½1 âˆˆ]0, 1[, m(ğ‘¡+1) lâ€™estimation courante du gradient utilise
lâ€™information sur les estimations passeÌes, stockeÌe dans m(ğ‘¡).
Une autre diffeÌrence importante entre SGD et la Adam consiste aÌ€ utiliser un taux dâ€™apprentissage adaptatif. En dâ€™autres
termes, au lieu dâ€™utiliser le meÌ‚me taux dâ€™apprentissage ğœŒpour tous les parameÌ€tres du modeÌ€le, le taux dâ€™apprentissage pour
un parameÌ€tre donneÌ ğœƒğ‘–est deÌfini comme :
Ì‚ğœŒ(ğ‘¡+1)(ğœƒğ‘–) =
ğœŒ
âˆšğ‘ (ğ‘¡+1)(ğœƒğ‘–) + ğœ–
ouÌ€ ğœ–est une constante petite devant 1 et
ğ‘ (ğ‘¡+1)(ğœƒğ‘–) =
1
1 âˆ’ğ›½ğ‘¡
2
[ğ›½2ğ‘ (ğ‘¡)(ğœƒğ‘–) + (1 âˆ’ğ›½2) (âˆ‡ğœƒğ‘–â„’)
2]
Ici aussi, le terme ğ‘ utilise le momentum. Par conseÌquent, le taux dâ€™apprentissage sera reÌduit pour les parameÌ€tres qui ont
subi de grandes mises aÌ€ jour dans les iteÌrations preÌceÌdentes.
Globalement, la reÌ€gle de mise aÌ€ jour dâ€™Adam est la suivante :
ğœƒ(ğ‘¡+1) â†ğœƒ(ğ‘¡) âˆ’
Ì‚ğœŒ(ğ‘¡+1)(ğœƒ)m(ğ‘¡+1)
4.3 La malÃ©diction de la profondeur
ConsideÌrons le reÌseau neuronal suivant :
w(0)
w(1)
w(2)
22
Chapitre 4. Optimisation


Introduction au Deep Learning (notes de cours)
et rappelons que, pour une couche donneÌe (â„“), la sortie de la couche est calculeÌe comme suit
ğ‘(â„“) = ğœ‘(ğ‘œ(â„“)) = ğœ‘(ğ‘¤(â„“âˆ’1)ğ‘(â„“âˆ’1))
ouÌ€ ğœ‘est la fonction dâ€™activation pour la couche donneÌe (nous ignorons les termes de biais dans cet exemple simplifieÌ).
Afin dâ€™effectuer une descente de gradient (stochastique), les gradients de la perte par rapport aux parameÌ€tres du modeÌ€le
doivent eÌ‚tre calculeÌs.
En utilisant la reÌ€gle de la deÌrivation en chaÃ®ne, ces gradients peuvent eÌ‚tre exprimeÌs comme suit :
ğœ•â„’
ğœ•ğ‘¤(2) = ğœ•â„’
ğœ•ğ‘(3)
ğœ•ğ‘(3)
ğœ•ğ‘œ(3)
ğœ•ğ‘œ(3)
ğœ•ğ‘¤(2)
ğœ•â„’
ğœ•ğ‘¤(1) = ğœ•â„’
ğœ•ğ‘(3)
ğœ•ğ‘(3)
ğœ•ğ‘œ(3)
ğœ•ğ‘œ(3)
ğœ•ğ‘(2)
ğœ•ğ‘(2)
ğœ•ğ‘œ(2)
ğœ•ğ‘œ(2)
ğœ•ğ‘¤(1)
ğœ•â„’
ğœ•ğ‘¤(0) = ğœ•â„’
ğœ•ğ‘(3)
ğœ•ğ‘(3)
ğœ•ğ‘œ(3)
ğœ•ğ‘œ(3)
ğœ•ğ‘(2)
ğœ•ğ‘(2)
ğœ•ğ‘œ(2)
ğœ•ğ‘œ(2)
ğœ•ğ‘(1)
ğœ•ğ‘(1)
ğœ•ğ‘œ(1)
ğœ•ğ‘œ(1)
ğœ•ğ‘¤(0)
Il y a des ideÌes importantes aÌ€ saisir ici.
Tout dâ€™abord, il faut remarquer que les poids qui sont plus eÌloigneÌs de la sortie du modeÌ€le heÌritent de reÌ€gles de gradient
composeÌes de plus de termes. Par conseÌquent, lorsque certains de ces termes deviennent de plus en plus petits, il y a un
risque plus eÌleveÌ pour ces poids que leurs gradients tombent aÌ€ 0. Câ€™est ce quâ€™on appelle lâ€™effet de gradient Ã©vanescent
(vanishing gradient), qui est un pheÌnomeÌ€ne treÌ€s courant dans les reÌseaux neuronaux profonds (câ€™est-aÌ€-dire les reÌseaux
composeÌs de nombreuses couches).
DeuxieÌ€mement, certains termes sont reÌpeÌteÌs dans ces formules, et en geÌneÌral, des termes de la forme ğœ•ğ‘(â„“)
ğœ•ğ‘œ(â„“) et
ğœ•ğ‘œ(â„“)
ğœ•ğ‘(â„“âˆ’1) sont
preÌsents aÌ€ plusieurs endroits. Ces termes peuvent eÌ‚tre deÌveloppeÌs comme suit :
ğœ•ğ‘(â„“)
ğœ•ğ‘œ(â„“) = ğœ‘â€²(ğ‘œ(â„“))
ğœ•ğ‘œ(â„“)
ğœ•ğ‘(â„“âˆ’1) = ğ‘¤(â„“âˆ’1)
Voyons aÌ€ quoi ressemblent les deÌriveÌes des fonctions dâ€™activation standard :
On peut constater que la deÌriveÌe de ReLU posseÌ€de une plus grande plage de valeurs dâ€™entreÌe pour lesquelles elle est non
nulle (typiquement toute la plage de valeurs dâ€™entreÌe positives) que ses concurrentes, ce qui en fait une fonction dâ€™activation
treÌ€s inteÌressante pour les reÌseaux neuronaux profonds, car nous avons vu que le terme ğœ•ğ‘(â„“)
ğœ•ğ‘œ(â„“) apparaÃ®t de manieÌ€re reÌpeÌteÌe
dans les deÌrivations en chaÃ®ne.
4.3. La malÃ©diction de la profondeur
23


Introduction au Deep Learning (notes de cours)
4.4 Coder tout cela en keras
Dans keras, les informations sur les pertes et lâ€™optimiseur sont transmises au moment de la compilation :
import keras
from keras.layers import Dense, InputLayer
from keras.models import Sequential
model = Sequential([
InputLayer(input_shape=(10, )),
Dense(units=20, activation="relu"),
Dense(units=3, activation="softmax")
])
model.summary()
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒLayer (type)
â”ƒOutput Shape
â”ƒ
Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚dense (Dense)
â”‚(None, 20)
â”‚
220 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚dense_1 (Dense)
â”‚(None, 3)
â”‚
63 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total params: 283 (1.11 KB)
Trainable params: 283 (1.11 KB)
Non-trainable params: 0 (0.00 B)
model.compile(loss="categorical_crossentropy", optimizer="adam")
En termes de pertes :
â€” "mse" est la perte dâ€™erreur quadratique moyenne,
â€” "binary_crossentropy" est la perte logistique pour la classification binaire,
â€” "categorical_crossentropy" est la perte logistique pour la classification multi-classes.
Les optimiseurs deÌfinis dans cette section sont disponibles sous forme de "sgd" et "adam". Afin dâ€™avoir le controÌ‚le sur
les hyper-parameÌ€tres des optimiseurs, on peut alternativement utiliser la syntaxe suivante :
from keras.optimizers import Adam, SGD
# Not a very good idea to tune beta_1
# and beta_2 parameters in Adam
adam_opt = Adam(learning_rate=0.001,
beta_1=0.9, beta_2=0.9)
# In order to use SGD with a custom learning rate:
# sgd_opt = SGD(learning_rate=0.001)
model.compile(loss="categorical_crossentropy", optimizer=adam_opt)
24
Chapitre 4. Optimisation


Introduction au Deep Learning (notes de cours)
4.5 PrÃ©traitement des donnÃ©es
En pratique, pour que la phase dâ€™ajustement du modeÌ€le se deÌroule correctement, il est important de mettre aÌ€ lâ€™eÌchelle les
donneÌes dâ€™entreÌe. Dans lâ€™exemple suivant, nous allons comparer deux entraÃ®nements du meÌ‚me modeÌ€le, avec une initialisa-
tion similaire et la seule diffeÌrence entre les deux sera de savoir si les donneÌes dâ€™entreÌe sont centreÌes-reÌduites ou laisseÌes
telles quelles.
import pandas as pd
from keras.utils import to_categorical
iris = pd.read_csv("../data/iris.csv", index_col=0)
iris = iris.sample(frac=1)
y = to_categorical(iris["target"])
X = iris.drop(columns=["target"])
from keras.layers import Dense, InputLayer
from keras.models import Sequential
from keras.utils import set_random_seed
set_random_seed(0)
model = Sequential([
InputLayer(input_shape=(4, )),
Dense(units=256, activation="relu"),
Dense(units=256, activation="relu"),
Dense(units=256, activation="relu"),
Dense(units=3, activation="softmax")
])
n_epochs = 100
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
h = model.fit(X, y, epochs=n_epochs, batch_size=30, verbose=0)
Standardisons maintenant nos donneÌes et comparons les performances obtenues :
X -= X.mean(axis=0)
X /= X.std(axis=0)
set_random_seed(0)
model = Sequential([
InputLayer(input_shape=(4, )),
Dense(units=256, activation="relu"),
Dense(units=256, activation="relu"),
Dense(units=256, activation="relu"),
Dense(units=3, activation="softmax")
])
n_epochs = 100
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
h_standardized = model.fit(X, y, epochs=n_epochs, batch_size=30, verbose=0)
4.5. PrÃ©traitement des donnÃ©es
25


Introduction au Deep Learning (notes de cours)
26
Chapitre 4. Optimisation


CHAPITRE 5
REÌGULARISATION
Comme nous lâ€™avons vu dans les chapitres preÌceÌdents, lâ€™une des forces des reÌseaux neuronaux est quâ€™ils peuvent approximer
nâ€™importe quelle fonction continue lorsquâ€™un nombre suffisant de parameÌ€tres est utiliseÌ. Lors de lâ€™utilisation dâ€™approxima-
teurs universels dans des contextes dâ€™apprentissage automatique, un risque connexe important est celui du surajustement
(overfitting) aux donneÌes dâ€™apprentissage. Plus formellement, eÌtant donneÌ un jeu de donneÌes dâ€™apprentissage ğ’Ÿğ‘¡tireÌ dâ€™une
distribution inconnue ğ’Ÿ, les parameÌ€tres du modeÌ€le sont optimiseÌs de manieÌ€re aÌ€ minimiser le risque empirique :
â„›ğ‘’(ğœƒ) =
1
|ğ’Ÿğ‘¡|
âˆ‘
(ğ‘¥ğ‘–,ğ‘¦ğ‘–)âˆˆğ’Ÿğ‘¡
â„’(ğ‘¥ğ‘–, ğ‘¦ğ‘–; ğ‘šğœƒ)
alors que le veÌritable objectif est de minimiser le Â« vrai Â» risque :
â„›(ğœƒ) = ğ”¼ğ‘¥,ğ‘¦âˆ¼ğ’Ÿâ„’(ğ‘¥, ğ‘¦; ğ‘šğœƒ)
et les deux objectifs nâ€™ont pas le meÌ‚me minimiseur.
Pour eÌviter cet eÌcueil, il faut utiliser des techniques de reÌgularisation, telles que celles preÌsenteÌes ci-apreÌ€s.
5.1 Early stopping
Comme illustreÌ ci-dessous, on peut observer que lâ€™entraÃ®nement dâ€™un reÌseau neuronal pendant un trop grand nombre
dâ€epochs peut conduire aÌ€ un surajustement. Notez quâ€™ici, le risque reÌel est estimeÌ graÌ‚ce aÌ€ lâ€™utilisation dâ€™un ensemble de
validation qui nâ€™est pas vu pendant lâ€™entraÃ®nement.
iris = pd.read_csv("../data/iris.csv", index_col=0)
iris = iris.sample(frac=1)
y = to_categorical(iris["target"])
X = iris.drop(columns=["target"])
X -= X.mean(axis=0)
X /= X.std(axis=0)
27


Introduction au Deep Learning (notes de cours)
import keras
from keras.layers import Dense, InputLayer
from keras.models import Sequential
from keras.utils import set_random_seed
set_random_seed(0)
model = Sequential([
InputLayer(input_shape=(4, )),
Dense(units=256, activation="relu"),
Dense(units=256, activation="relu"),
Dense(units=256, activation="relu"),
Dense(units=3, activation="softmax")
])
n_epochs = 100
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
h = model.fit(X, y, validation_split=0.3, epochs=n_epochs, batch_size=30, verbose=0)
Ici, le meilleur modeÌ€le (en termes de capaciteÌs de geÌneÌralisation) semble eÌ‚tre le modeÌ€le aÌ€ lâ€epoch np.int64(23). En
dâ€™autres termes, si nous avions arreÌ‚teÌ le processus dâ€™apprentissage apreÌ€s lâ€epoch np.int64(23), nous aurions obtenu un
meilleur modeÌ€le que si nous utilisons le modeÌ€le entraÃ®neÌ pendant 70 epochs.
Câ€™est toute lâ€™ideÌe derrieÌ€re la strateÌgie dâ€early stopping, qui consiste aÌ€ arreÌ‚ter le processus dâ€™apprentissage deÌ€s que la perte
de validation cesse de sâ€™ameÌliorer. Cependant, comme on peut le voir dans la visualisation ci-dessus, la perte de validation
a tendance aÌ€ osciller, et on attend souvent plusieurs epochs avant de supposer que la perte a peu de chances de sâ€™ameÌliorer
dans le futur. Le nombre dâ€epochs aÌ€ attendre est appeleÌ le parameÌ€tre de patience.
Dans keras, lâ€™arreÌ‚t anticipeÌ peut eÌ‚tre configureÌ via un callback, comme dans lâ€™exemple suivant :
from keras.callbacks import EarlyStopping
set_random_seed(0)
(suite sur la page suivante)
28
Chapitre 5. RÃ©gularisation


Introduction au Deep Learning (notes de cours)
(suite de la page preÌceÌdente)
model = Sequential([
InputLayer(input_shape=(4, )),
Dense(units=256, activation="relu"),
Dense(units=256, activation="relu"),
Dense(units=256, activation="relu"),
Dense(units=3, activation="softmax")
])
cb_es = EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True)
n_epochs = 100
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
h = model.fit(X, y,
validation_split=0.3, epochs=n_epochs, batch_size=30,
verbose=0, callbacks=[cb_es])
Et maintenant, meÌ‚me si le modeÌ€le eÌtait preÌvu pour eÌ‚tre entraÃ®neÌ pendant 70 epochs, lâ€™entraÃ®nement est arreÌ‚teÌ deÌ€s quâ€™il
atteint 10 epochs conseÌcutives sans ameÌlioration de la perte de validation, et les parameÌ€tres du modeÌ€le sont restaureÌs
comme les parameÌ€tres du modeÌ€le aÌ€ lâ€epoch np.int64(23).
5.2 PÃ©nalisation de la perte
Une autre faÃ§on importante dâ€™appliquer la reÌgularisation dans les reÌseaux neuronaux est la peÌnalisation des pertes. Un
exemple typique de cette strateÌgie de reÌgularisation est la reÌgularisation L2. Si nous deÌsignons par â„’ğ‘Ÿla perte reÌgulariseÌe
par L2, elle peut eÌ‚tre exprimeÌe comme suit :
â„’ğ‘Ÿ(ğ’Ÿ; ğ‘šğœƒ) = â„’(ğ’Ÿ; ğ‘šğœƒ) + ğœ†âˆ‘
â„“
â€–ğœƒ(â„“)â€–2
2
ouÌ€ ğœƒ(â„“) est la matrice de poids de la couche â„“.
Cette reÌgularisation tend aÌ€ reÌduire les grandes valeurs des parameÌ€tres pendant le processus dâ€™apprentissage, ce qui est
connu pour aider aÌ€ ameÌliorer la geÌneÌralisation.
5.2. PÃ©nalisation de la perte
29


Introduction au Deep Learning (notes de cours)
En keras, ceci est impleÌmenteÌ comme :
from keras.regularizers import L2
Î» = 0.01
set_random_seed(0)
model = Sequential([
InputLayer(input_shape=(4, )),
Dense(units=256, activation="relu", kernel_regularizer=L2(Î»)),
Dense(units=256, activation="relu", kernel_regularizer=L2(Î»)),
Dense(units=256, activation="relu", kernel_regularizer=L2(Î»)),
Dense(units=3, activation="softmax")
])
n_epochs = 100
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
h = model.fit(X, y, validation_split=0.3, epochs=n_epochs, batch_size=30, verbose=0)
5.3 DropOut
Dans cette section, nous preÌsentons la strateÌgie DropOut, qui a eÌteÌ introduite dans [Srivastava et al., 2014]. Lâ€™ideÌe derrieÌ€re
le DropOut est dâ€™eÌteindre certains neurones pendant lâ€™apprentissage. Les neurones deÌsactiveÌs changent aÌ€ chaque minibatch
de sorte que, globalement, tous les neurones sont entraÃ®neÌs pendant tout le processus.
Le concept est treÌ€s similaire dans lâ€™esprit aÌ€ une strateÌgie utiliseÌe pour lâ€™entraÃ®nement des foreÌ‚ts aleÌatoires, qui consiste
aÌ€ seÌlectionner aleÌatoirement des variables candidates pour chaque division dâ€™arbre aÌ€ lâ€™inteÌrieur dâ€™une foreÌ‚t, ce qui est
connu pour conduire aÌ€ de meilleures performances de geÌneÌralisation pour les foreÌ‚ts aleÌatoires. La principale diffeÌrence
ici est que lâ€™on peut non seulement deÌsactiver les neurones dâ€™entrÃ©e mais aussi les neurones de la couche cachÃ©e pendant
lâ€™apprentissage.
Dans keras, ceci est impleÌmenteÌ comme une couche, qui agit en deÌsactivant les neurones de la couche preÌceÌdente dans
le reÌseau :
30
Chapitre 5. RÃ©gularisation


Introduction au Deep Learning (notes de cours)
FĞ†ÔŒ. 5.1 â€“ Illustration du meÌcanisme de DropOut. Afin dâ€™entraÃ®ner un modeÌ€le donneÌ (aÌ€ gauche), aÌ€ chaque minibatch, une
proportion donneÌe de neurones est choisie au hasard pour eÌ‚tre Â« deÌsactiveÌe Â» et le sous-reÌseau reÌsultant est utiliseÌ pour
lâ€™eÌtape dâ€™optimisation en cours (cf. figure de droite, dans laquelle 40% des neurones â€“ coloreÌs en gris â€“ sont deÌsactiveÌs).
from keras.layers import Dropout
set_random_seed(0)
switchoff_proba = 0.3
model = Sequential([
InputLayer(input_shape=(4, )),
Dropout(rate=switchoff_proba),
Dense(units=256, activation="relu"),
Dropout(rate=switchoff_proba),
Dense(units=256, activation="relu"),
Dropout(rate=switchoff_proba),
Dense(units=256, activation="relu"),
Dropout(rate=switchoff_proba),
Dense(units=3, activation="softmax")
])
n_epochs = 100
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
h = model.fit(X, y, validation_split=0.3, epochs=n_epochs, batch_size=30, verbose=0)
5.3. DropOut
31


Introduction au Deep Learning (notes de cours)
Â® Exercice #1
En observant les valeurs de perte dans la figure ci-dessus, pouvez-vous expliquer pourquoi la perte de validation est
presque systeÌmatiquement infeÌrieure aÌ€ celle calculeÌe sur le jeu dâ€™apprentissage?
Â® Solution
En fait, la perte dâ€™apprentissage est calculeÌe comme la perte moyenne sur tous les minibatchs dâ€™apprentissage
pendant une epoch. Si nous nous rappelons que pendant lâ€™apprentissage, aÌ€ chaque minibatch, 30% des neurones
sont deÌsactiveÌs, on peut voir que seule une sous-partie du modeÌ€le complet est utiliseÌe lors de lâ€™eÌvaluation de la
perte dâ€™apprentissage alors que le modeÌ€le complet est utiliseÌ lors de la preÌdiction sur lâ€™ensemble de validation, ce
qui explique pourquoi la perte de validation mesureÌe est infeÌrieure aÌ€ celle de lâ€™apprentissage.
32
Chapitre 5. RÃ©gularisation


CHAPITRE 6
REÌSEAUX NEURONAUX CONVOLUTIFS
Les reÌseaux de neurones convolutifs (aussi appeleÌs ConvNets) sont conÃ§us pour tirer parti de la structure des donneÌes.
Dans ce chapitre, nous aborderons deux types de reÌseaux convolutifs : nous commencerons par le cas monodimensionnel
et verrons comment les reÌseaux convolutifs aÌ€ convolutions 1D peuvent eÌ‚tre utiles pour traiter les seÌries temporelles. Nous
preÌsenterons ensuite le cas 2D, particulieÌ€rement utile pour traiter les donneÌes dâ€™image.
6.1 RÃ©seaux de neurones convolutifs pour les sÃ©ries temporelles
Les reÌseaux de neurones convolutifs pour les seÌries temporelles reposent sur lâ€™opeÌrateur de convolution 1D qui, eÌtant
donneÌ une seÌrie temporelle x et un filtre f, calcule une carte dâ€™activation comme :
(x âˆ—f) (ğ‘¡) =
ğ¿
âˆ‘
ğ‘˜=âˆ’ğ¿
ğ‘“ğ‘˜ğ‘¥ğ‘¡+ğ‘˜
(6.1)
ouÌ€ le filtre f est de longueur (2ğ¿+ 1).
Le code suivant illustre cette notion en utilisant un filtre gaussien :
Les reÌseaux de neurones convolutifs sont constitueÌs de blocs de convolution dont les parameÌ€tres sont les coefficients des
filtres quâ€™ils inteÌ€grent (les filtres ne sont donc pas fixeÌs a priori comme dans lâ€™exemple ci-dessus mais plutoÌ‚t appris). Ces
blocs de convolution sont eÌquivariants par translation, ce qui signifie quâ€™un deÌcalage (temporel) de leur entreÌe entraÃ®ne le
meÌ‚me deÌcalage temporel de leur sortie :
/tmp/ipykernel_7364/1028966743.py:32: UserWarning: This figure includes Axes thatâ£
â†ªare not compatible with tight_layout, so results might be incorrect.
plt.tight_layout()
<IPython.core.display.HTML object>
Les modeÌ€les convolutifs sont connus pour eÌ‚tre treÌ€s performants dans les applications de vision par ordinateur, utilisant
des quantiteÌs modeÌreÌes de parameÌ€tres par rapport aux modeÌ€les entieÌ€rement connecteÌs (bien suÌ‚r, des contre-exemples
existent, et le terme Â« modeÌreÌ Â» est particulieÌ€rement vague).
33


Introduction au Deep Learning (notes de cours)
La plupart des architectures standard de seÌries temporelles qui reposent sur des blocs convolutionnels sont des adaptations
directes de modeÌ€les de la communauteÌ de la vision par ordinateur ([Le Guennec et al., 2016] sâ€™appuie sur une alternance
entre couches de convolution et couches de pooling, tandis que des travaux plus reÌcents sâ€™appuient sur des connexions
reÌsiduelles et des modules dâ€inception [Fawaz et al., 2020]). Ces blocs de base (convolution, pooling, couches reÌsiduelles)
sont discuteÌs plus en deÌtail dans la section suivante.
Ces modeÌ€les de classification des seÌries temporelles (et bien dâ€™autres) sont preÌsenteÌs et eÌvalueÌs dans [Fawaz et al., 2019]
que nous conseillons au lecteur inteÌresseÌ.
6.2 RÃ©seaux de neurones convolutifs pour les images
Nous allons maintenant nous inteÌresser au cas 2D, dans lequel les filtres de convolution ne glisseront pas sur un seul axe
comme dans le cas des seÌries temporelles, mais plutoÌ‚t sur les deux dimensions (largeur et hauteur) dâ€™une image.
6.2.1 Images et convolutions
Comme on le voit ci-dessous, une image est une grille de pixels, et chaque pixel a une valeur dâ€™intensiteÌ dans chacun des
canaux de lâ€™image. Les images couleur sont typiquement composeÌes de 3 canaux (ici Rouge, Vert et Bleu).
FĞ†ÔŒ. 6.1 â€“ Une image et ses 3 canaux (intensiteÌs de Rouge, Vert et Bleu, de gauche aÌ€ droite).
La sortie dâ€™une convolution sur une image x est une nouvelle image, dont les valeurs des pixels peuvent eÌ‚tre calculeÌes
comme suit :
(x âˆ—f) (ğ‘–, ğ‘—) =
ğ¾
âˆ‘
ğ‘˜=âˆ’ğ¾
ğ¿
âˆ‘
ğ‘™=âˆ’ğ¿
3
âˆ‘
ğ‘=1
ğ‘“ğ‘˜,ğ‘™,ğ‘ğ‘¥ğ‘–+ğ‘˜,ğ‘—+ğ‘™,ğ‘.
(6.2)
En dâ€™autres termes, les pixels de lâ€™image de sortie sont calculeÌs comme le produit scalaire entre un filtre de convolution
(qui est un tenseur de forme (2ğ¾+ 1, 2ğ¿+ 1, ğ‘)) et un patch dâ€™image centreÌ aÌ€ la position donneÌe.
ConsideÌrons, par exemple, le filtre de convolution 9x9 suivant :
34
Chapitre 6. RÃ©seaux neuronaux convolutifs


Introduction au Deep Learning (notes de cours)
Le reÌsultat de la convolution de lâ€™image de chat ci-dessus avec ce filtre est lâ€™image suivante en niveaux de gris (câ€™est-aÌ€-dire
constitueÌe dâ€™un seul canal) :
On peut remarquer que cette image est une version floue de lâ€™image originale. Câ€™est parce que nous avons utiliseÌ un filtre
Gaussien. Comme pour les seÌries temporelles, lors de lâ€™utilisation dâ€™opeÌrations de convolution dans les reÌseaux neuronaux,
le contenu des filtres sera appris, plutoÌ‚t que deÌfini a priori.
6.2. RÃ©seaux de neurones convolutifs pour les images
35


Introduction au Deep Learning (notes de cours)
6.2.2 RÃ©seaux convolutifs de type LeNet
Dans [LeCun et al., 1998], un empilement de couches de convolution, de pooling et de couches entieÌ€rement connecteÌes
est introduit pour une taÌ‚che de classification dâ€™images, plus speÌcifiquement une application de reconnaissance de chiffres.
Le reÌseau neuronal reÌsultant, appeleÌ LeNet, est repreÌsenteÌ ci-dessous :
FĞ†ÔŒ. 6.2 â€“ ModeÌ€le LeNet-5
Couches de convolution
Une couche de convolution est constitueÌe de plusieurs filtres de convolution (eÌgalement appeleÌs kernels) qui opeÌ€rent
en paralleÌ€le sur la meÌ‚me image dâ€™entreÌe. Chaque filtre de convolution geÌneÌ€re une carte dâ€™activation en sortie et toutes
ces cartes sont empileÌes pour former la sortie de la couche de convolution. Tous les filtres dâ€™une couche partagent la
meÌ‚me largeur et la meÌ‚me hauteur. Un terme de biais et une fonction dâ€™activation peuvent eÌ‚tre utiliseÌs dans les couches de
convolution, comme dans dâ€™autres couches de reÌseaux neuronaux. Dans lâ€™ensemble, la sortie dâ€™un filtre de convolution est
calculeÌe comme suit :
(x âˆ—f) (ğ‘–, ğ‘—, ğ‘) = ğœ‘(
ğ¾
âˆ‘
ğ‘˜=âˆ’ğ¾
ğ¿
âˆ‘
ğ‘™=âˆ’ğ¿
âˆ‘
ğ‘â€²
ğ‘“ğ‘
ğ‘˜,ğ‘™,ğ‘â€²ğ‘¥ğ‘–+ğ‘˜,ğ‘—+ğ‘™,ğ‘â€² + ğ‘ğ‘)
(6.3)
ouÌ€ ğ‘deÌsigne le canal de sortie (notez que chaque canal de sortie est associeÌ aÌ€ un filtre ğ‘“ğ‘), ğ‘ğ‘est le terme de biais qui lui
est associeÌ et ğœ‘est la fonction dâ€™activation utiliseÌe.
b Astuce
En keras, une telle couche est impleÌmenteÌe aÌ€ lâ€™aide de la classe Conv2D :
import keras
from keras.layers import Conv2D
layer = Conv2D(filters=6, kernel_size=5, padding="valid", activation="relu")
Â® Padding
36
Chapitre 6. RÃ©seaux neuronaux convolutifs


Introduction au Deep Learning (notes de cours)
FĞ†ÔŒ. 6.3 â€“ Visualisation de lâ€™effet du padding (source: V. Dumoulin, F. Visin - A guide to convolution arithmetic for
deep learning). Gauche: sans padding, droite: avec padding.
Lors du traitement dâ€™une image dâ€™entreÌe, il peut eÌ‚tre utile de sâ€™assurer que la carte de caracteÌristiques (ou carte dâ€™ac-
tivation) de sortie a la meÌ‚me largeur et la meÌ‚me hauteur que lâ€™image dâ€™entreÌe. Cela peut eÌ‚tre reÌaliseÌ en agrandissant
artificiellement lâ€™image dâ€™entreÌe et en remplissant les zones ajouteÌes avec des zeÌros, comme illustreÌ dans Fig. 6.3 dans
lequel la zone de padding est repreÌsenteÌe en blanc.
Couches de pooling
Les couches de pooling effectuent une opeÌration de sous-eÌchantillonnage qui reÌsume en quelque sorte les informations
contenues dans les cartes de caracteÌristiques dans des cartes aÌ€ plus faible reÌsolution.
Lâ€™ideÌe est de calculer, pour chaque parcelle dâ€™image, une caracteÌristique de sortie qui calcule un agreÌgat des pixels de
la parcelle. Les opeÌrateurs dâ€™agreÌgation typiques sont les opeÌrateurs de moyenne (dans ce cas, la couche correspondante
est appeleÌe average pooling) ou de maximum (pour les couches de max pooling). Afin de reÌduire la reÌsolution des cartes
de sortie, ces agreÌgats sont geÌneÌralement calculeÌs sur des feneÌ‚tres glissantes qui ne se chevauchent pas, comme illustreÌ
ci-dessous, pour un max pooling avec une taille de pooling de 2x2 :
6.2. RÃ©seaux de neurones convolutifs pour les images
37


Introduction au Deep Learning (notes de cours)
max
Ces couches eÌtaient largement utiliseÌes historiquement dans les premiers modeÌ€les convolutifs et le sont de moins en moins
aÌ€ mesure que la puissance de calcul disponible augmente.
b Astuce
En keras, les couches de pooling sont impleÌmenteÌes aÌ€ travers les classes MaxPool2D et AvgPool2D :
from keras.layers import MaxPool2D, AvgPool2D
max_pooling_layer = MaxPool2D(pool_size=2)
average_pooling_layer = AvgPool2D(pool_size=2)
Ajout dâ€™une tÃªte de classification
Un empilement de couches de convolution et de pooling produit une carte dâ€™activation structureÌe (qui prend la forme dâ€™une
grille 2d avec une dimension suppleÌmentaire pour les diffeÌrents canaux). Lorsque lâ€™on vise une taÌ‚che de classification
dâ€™images, lâ€™objectif est de produire la classe la plus probable pour lâ€™image dâ€™entreÌe, ce qui est geÌneÌralement reÌaliseÌ par une
teÌ‚te de classification (classification head) composeÌe de couches entieÌ€rement connecteÌes.
Pour que la teÌ‚te de classification soit capable de traiter une carte dâ€™activation, les informations de cette carte doivent eÌ‚tre
transformeÌes en un vecteur. Cette opeÌration est appeleÌe Flatten dans keras, et le modeÌ€le correspondant aÌ€ Fig. 6.2 peut
eÌ‚tre impleÌmenteÌ comme :
from keras.models import Sequential
from keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense
model = Sequential([
(suite sur la page suivante)
38
Chapitre 6. RÃ©seaux neuronaux convolutifs


Introduction au Deep Learning (notes de cours)
(suite de la page preÌceÌdente)
InputLayer(input_shape=(32, 32, 1)),
Conv2D(filters=6, kernel_size=5, padding="valid", activation="relu"),
MaxPool2D(pool_size=2),
Conv2D(filters=16, kernel_size=5, padding="valid", activation="relu"),
MaxPool2D(pool_size=2),
Flatten(),
Dense(120, activation="relu"),
Dense(84, activation="relu"),
Dense(10, activation="softmax")
])
model.summary()
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒLayer (type)
â”ƒOutput Shape
â”ƒ
Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚conv2d (Conv2D)
â”‚(None, 28, 28, 6)
â”‚
156 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚max_pooling2d (MaxPooling2D)
â”‚(None, 14, 14, 6)
â”‚
0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚conv2d_1 (Conv2D)
â”‚(None, 10, 10, 16)
â”‚
2,416 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚max_pooling2d_1 (MaxPooling2D)
â”‚(None, 5, 5, 16)
â”‚
0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚flatten (Flatten)
â”‚(None, 400)
â”‚
0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚dense (Dense)
â”‚(None, 120)
â”‚
48,120 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚dense_1 (Dense)
â”‚(None, 84)
â”‚
10,164 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚dense_2 (Dense)
â”‚(None, 10)
â”‚
850 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total params: 61,706 (241.04 KB)
Trainable params: 61,706 (241.04 KB)
Non-trainable params: 0 (0.00 B)
6.2. RÃ©seaux de neurones convolutifs pour les images
39


Introduction au Deep Learning (notes de cours)
40
Chapitre 6. RÃ©seaux neuronaux convolutifs


CHAPITRE 7
REÌSEAUX NEURONAUX REÌCURRENTS
Les reÌseaux neuronaux reÌcurrents (RNN) traitent les eÌleÌments dâ€™une seÌrie temporelle un par un. Typiquement, aÌ€ lâ€™instant
ğ‘¡, un bloc reÌcurrent prend en entreÌe :
â€” lâ€™entreÌe courante ğ‘¥ğ‘¡et
â€” un eÌtat cacheÌ â„ğ‘¡âˆ’1 qui a pour but de reÌsumer les informations cleÌs provenant de des entreÌes passeÌes {ğ‘¥0, â€¦ , ğ‘¥ğ‘¡âˆ’1}
Ce bloc retourne un eÌtat cacheÌ mis aÌ€ jour â„ğ‘¡:
â€¦
â€¦
â„ğ‘¡
ğ‘¥ğ‘¡
â„ğ‘¡âˆ’1
ğ‘¥ğ‘¡âˆ’1
â„ğ‘¡+1
ğ‘¥ğ‘¡+1
Il existe diffeÌrentes couches reÌcurrentes qui diffeÌ€rent principalement par la faÃ§on dont â„ğ‘¡est calculeÌe.
41


Introduction au Deep Learning (notes de cours)
7.1 RÃ©seaux rÃ©currents standard
La formulation originale dâ€™une RNN est la suivante :
âˆ€ğ‘¡, â„ğ‘¡= tanh(ğ‘Šâ„â„ğ‘¡âˆ’1 + ğ‘Šğ‘¥ğ‘¥ğ‘¡+ ğ‘)
(7.1)
ouÌ€ ğ‘Šâ„est une matrice de poids associeÌe au traitement de lâ€™eÌtat cacheÌ preÌceÌdent, ğ‘Šğ‘¥est une autre matrice de poids
associeÌe au traitement de la lâ€™entreÌe actuelle et ğ‘est un terme de biais.
On notera ici que ğ‘Šâ„, ğ‘Šğ‘¥et ğ‘ne sont pas indexeÌs par ğ‘¡, ce qui signifie que quâ€™ils sont partagÃ©s entre tous les temps.
Une limitation importante de cette formule est quâ€™elle eÌchoue aÌ€ capturer les deÌpendances aÌ€ long terme. Pour mieux
comprendre pourquoi, il faut se rappeler que les parameÌ€tres de ces reÌseaux sont optimiseÌs par des algorithmes de descente
de gradient stochastique.
Pour simplifier les notations, consideÌrons un cas simplifieÌ dans lequel â„ğ‘¡et ğ‘¥ğ‘¡sont tous deux des valeurs scalaires, et
regardons ce que vaut le gradient de la sortie â„ğ‘¡par rapport aÌ€ ğ‘Šâ„(qui est alors aussi un scalaire) :
âˆ‡ğ‘Šâ„(â„ğ‘¡) = tanhâ€²(ğ‘œğ‘¡) â‹…ğœ•ğ‘œğ‘¡
ğœ•ğ‘Šâ„
(7.2)
ouÌ€ ğ‘œğ‘¡= ğ‘Šâ„â„ğ‘¡âˆ’1 + ğ‘Šğ‘¥ğ‘¥ğ‘¡+ ğ‘, donc:
ğœ•ğ‘œğ‘¡
ğœ•ğ‘Šâ„
= â„ğ‘¡âˆ’1 + ğ‘Šâ„â‹…ğœ•â„ğ‘¡âˆ’1
ğœ•ğ‘Šâ„
.
(7.3)
Ici, la forme de ğœ•â„ğ‘¡âˆ’1
ğœ•ğ‘Šâ„sera similaire aÌ€ celle de âˆ‡ğ‘Šâ„(â„ğ‘¡) ci-dessus, et, au final, on obtient :
âˆ‡ğ‘Šâ„(â„ğ‘¡)
=
tanhâ€²(ğ‘œğ‘¡) â‹…[â„ğ‘¡âˆ’1 + ğ‘Šâ„â‹…ğœ•â„ğ‘¡âˆ’1
ğœ•ğ‘Šâ„
]
(7.4)
=
tanhâ€²(ğ‘œğ‘¡) â‹…[â„ğ‘¡âˆ’1 + ğ‘Šâ„â‹…tanhâ€²(ğ‘œğ‘¡âˆ’1) â‹…[â„ğ‘¡âˆ’2 + ğ‘Šâ„â‹…[â€¦ ]]]
(7.5)
=
â„ğ‘¡âˆ’1tanhâ€²(ğ‘œğ‘¡) + â„ğ‘¡âˆ’2ğ‘Šâ„tanhâ€²(ğ‘œğ‘¡)tanhâ€²(ğ‘œğ‘¡âˆ’1) + â€¦
(7.6)
=
ğ‘¡âˆ’1
âˆ‘
ğ‘¡â€²=1
â„ğ‘¡â€² [ğ‘Šğ‘¡âˆ’ğ‘¡â€²âˆ’1
â„
tanhâ€²(ğ‘œğ‘¡â€²+1) â‹…â‹¯â‹…tanhâ€²(ğ‘œğ‘¡)]
(7.7)
En dâ€™autres termes, lâ€™influence de â„ğ‘¡â€² sera atteÌnueÌe par un facteur ğ‘Šğ‘¡âˆ’ğ‘¡â€²âˆ’1
â„
tanhâ€²(ğ‘œğ‘¡â€²+1) â‹…â‹¯â‹…tanhâ€²(ğ‘œğ‘¡).
Rappelons maintenant aÌ€ quoi ressemblent la fonction tanh et sa deÌriveÌe :
42
Chapitre 7. RÃ©seaux neuronaux rÃ©currents


Introduction au Deep Learning (notes de cours)
On peut voir aÌ€ quel point les gradients se rapprochent rapidement de 0 pour des entreÌes plus grandes (en valeur absolue)
que 2, et avoir plusieurs termes de ce type dans une deÌrivation en chaÃ®ne fera tendre les termes correspondants vers 0.
En dâ€™autres termes, le gradient de lâ€™eÌtat cacheÌ au temps ğ‘¡sera seulement influenceÌ par quelques uns de ses preÌdeÌcesseurs
{â„ğ‘¡âˆ’1, â„ğ‘¡âˆ’2, â€¦ } et les les deÌpendances aÌ€ long terme seront ignoreÌes lors de lâ€™actualisation des parameÌ€tres du modeÌ€le par
descente de gradient. Il sâ€™agit dâ€™une occurrence dâ€™un pheÌnomeÌ€ne plus geÌneÌral connu sous le nom de vanishing gradient.
7.2 Long Short Term Memory
Les blocs Long Short Term Memory (LSTM, [Hochreiter and Schmidhuber, 1997]) ont eÌteÌ conÃ§us comme une alternative
aÌ€ aux blocs reÌcurrents classiques. Ils visent aÌ€ atteÌnuer lâ€™effet de vanishing gradient par lâ€™utilisation de portes qui codent
explicitement quelle partie de lâ€™information doit (resp. ne doit pas) eÌ‚tre utiliseÌe.
Â® Les portes dans les rÃ©seaux neuronaux
Dans la terminologie des reÌseaux de neurones, une porte ğ‘”âˆˆ[0, 1]ğ‘‘est un vecteur utiliseÌ pour filtrer les informations
dâ€™un vecteur caracteÌristique entrant ğ‘£âˆˆâ„ğ‘‘de telle sorte que le reÌsultat de lâ€™application de la porte est : ğ‘”âŠ™ğ‘£. ouÌ€ âŠ™
est le produit eÌleÌment-par-eÌleÌment. La porte ğ‘”aura donc tendance aÌ€ supprimer une partie des caracteÌristiques de ğ‘£.
(celles qui correspondent aÌ€ des valeurs treÌ€s faibles de ğ‘”).
Dans ces blocs, un eÌtat suppleÌmentaire est utiliseÌ, appeleÌ eÌtat de la cellule ğ¶ğ‘¡. Cet eÌtat est calculeÌ comme suit :
ğ¶ğ‘¡= ğ‘“ğ‘¡âŠ™ğ¶ğ‘¡âˆ’1 + ğ‘–ğ‘¡âŠ™
Ìƒ
ğ¶ğ‘¡
(7.8)
ouÌ€ ğ‘“ğ‘¡est appeleÌe forget gate (elle pousse le reÌseau aÌ€ oublier les parties inutiles de lâ€™eÌtat passeÌ de la cellule), ğ‘–ğ‘¡est lâ€input
7.2. Long Short Term Memory
43


Introduction au Deep Learning (notes de cours)
gate et
Ìƒ
ğ¶ğ‘¡est une version actualiseÌe de lâ€™eÌtat de la cellule (qui, aÌ€ son tour, peut eÌ‚tre partiellement censureÌe par lâ€input
gate).
Laissons de coÌ‚teÌ pour lâ€™instant les deÌtails concernant le calcul de ces 3 termes et concentrons-nous plutoÌ‚t sur la faÃ§on dont
la formule ci-dessus est est significativement diffeÌrente de la reÌ€gle de mise aÌ€ jour de lâ€™eÌtat cacheÌ dans le modeÌ€le classique.
En effet, dans ce cas, si le reÌseau lâ€™apprend (par lâ€™intermeÌdiaire de ğ‘“ğ‘¡), lâ€™information compleÌ€te de lâ€™eÌtat preÌceÌdent de la
cellule ğ¶ğ‘¡âˆ’1 peut eÌ‚tre reÌcupeÌreÌe, ce qui permet aux gradients de se propager aÌ€ rebours de lâ€™axe du temps (et de ne plus
disparaÃ®tre).
Alors, le lien entre lâ€™eÌtat de la cellule et lâ€™eÌtat cacheÌ est :
â„ğ‘¡= ğ‘œğ‘¡âŠ™tanh(ğ¶ğ‘¡) .
(7.9)
En dâ€™autres termes, lâ€™eÌtat cacheÌ est la version transformeÌe (par la fonction tanh) de lâ€™eÌtat de la cellule, encore censureÌ par
une porte de sortie (output gate) ğ‘œğ‘¡.
Toutes les portes utiliseÌes dans les formules ci-dessus sont deÌfinies de manieÌ€re similaire :
ğ‘“ğ‘¡
=
ğœ(ğ‘Šğ‘“â‹…[â„ğ‘¡âˆ’1, ğ‘¥ğ‘¡] + ğ‘ğ‘“)
(7.10)
ğ‘–ğ‘¡
=
ğœ(ğ‘Šğ‘–â‹…[â„ğ‘¡âˆ’1, ğ‘¥ğ‘¡] + ğ‘ğ‘–)
(7.11)
ğ‘œğ‘¡
=
ğœ(ğ‘Šğ‘œâ‹…[â„ğ‘¡âˆ’1, ğ‘¥ğ‘¡] + ğ‘ğ‘œ)
(7.12)
ouÌ€ ğœest la fonction dâ€™activation sigmoÃ¯de (dont les valeurs sont comprises dans [0, 1]) et [â„ğ‘¡âˆ’1, ğ‘¥ğ‘¡] la concateÌnation des
caracteÌristiques â„ğ‘¡âˆ’1 et ğ‘¥ğ‘¡.
Enfin, lâ€™eÌtat de cellule mis aÌ€ jour
Ìƒ
ğ¶ğ‘¡est calculeÌ comme suit :
Ìƒ
ğ¶ğ‘¡= tanh(ğ‘Šğ¶â‹…[â„ğ‘¡âˆ’1, ğ‘¥ğ‘¡] + ğ‘ğ¶) .
(7.13)
Il existe dans la litteÌrature de nombreuses variantes de ces blocs LSTM qui reposent toujours sur les meÌ‚mes principes de
base.
7.3 Gated Recurrent Unit
Une parameÌtrisation leÌgeÌ€rement diffeÌrente dâ€™un bloc reÌcurrent est utiliseÌe dans les Gated Recurrent Units (GRU, [Cho et
al., 2014]).
Les GRUs reposent eÌgalement sur lâ€™utilisation de portes pour laisser (de manieÌ€re adaptative) lâ€™information circuler aÌ€
travers le temps. Une premieÌ€re diffeÌrence significative entre les GRUs et les LSTMs est que les GRUs nâ€™ont pas recours
aÌ€ lâ€™utilisation dâ€™un eÌtat de cellule. Au lieu de cela, la reÌ€gle de mise aÌ€ jour de lâ€™eÌtat cacheÌ est la suivante :
â„ğ‘¡= (1 âˆ’ğ‘§ğ‘¡) âŠ™â„ğ‘¡âˆ’1 + ğ‘§ğ‘¡âŠ™Ìƒâ„ğ‘¡
(7.14)
ouÌ€ ğ‘§ğ‘¡est une porte qui eÌquilibre (par caracteÌristique) la quantiteÌ dâ€™informations qui est conserveÌe de lâ€™eÌtat cacheÌ preÌceÌdent
avec la quantiteÌ dâ€™informations qui doit eÌ‚tre mise aÌ€ jour en utilisant le nouvel eÌtat cacheÌ candidat Ìƒâ„ğ‘¡, calculeÌ comme suit :
Ìƒâ„ğ‘¡= tanh(ğ‘Šâ‹…[ğ‘Ÿğ‘¡âŠ™â„ğ‘¡âˆ’1, ğ‘¥ğ‘¡] + ğ‘) ,
(7.15)
ouÌ€ ğ‘Ÿğ‘¡est une porte suppleÌmentaire qui peut cacher une partie de lâ€™eÌtat cacheÌ preÌceÌdent.
Les formules pour les portes ğ‘§ğ‘¡et ğ‘Ÿğ‘¡sont similaires aÌ€ celles fournies pour ğ‘“ğ‘¡, ğ‘–ğ‘¡et ğ‘œğ‘¡dans le cas des LSTMs.
Une eÌtude graphique de la capaciteÌ de ces variantes de reÌseaux reÌcurrents aÌ€ apprendre des deÌpendances aÌ€ long terme est
fournie dans [Madsen, 2019].
44
Chapitre 7. RÃ©seaux neuronaux rÃ©currents


Introduction au Deep Learning (notes de cours)
7.4 Conclusion
Dans ce chapitre et le preÌceÌdent, nous avons passeÌ en revue les architectures de reÌseaux de neurones qui sont utiliseÌes
pour apprendre aÌ€ partir de donneÌes temporelles ou seÌquentielles. En raison de contraintes de temps, nous nâ€™avons pas
abordeÌ les modeÌ€les baseÌs sur lâ€™attention dans ce cours. Nous avons preÌsenteÌ les modeÌ€les convolutifs qui visent aÌ€ extraire
des formes locales discriminantes dans les seÌries et les modeÌ€les reÌcurrents qui exploitent plutoÌ‚t la notion de seÌquence.
Concernant ces derniers, des variantes visant aÌ€ faire face aÌ€ lâ€™effet de gradient eÌvanescent ont eÌteÌ introduites. Il est aÌ€ noter
que les modeÌ€les reÌcurrents sont connus pour neÌcessiter plus de donneÌes dâ€™entraÃ®nement que leurs homologues convolutifs.
7.4. Conclusion
45


Introduction au Deep Learning (notes de cours)
46
Chapitre 7. RÃ©seaux neuronaux rÃ©currents


CHAPITRE 8
MEÌCANISME Dâ€™ATTENTION
Dans de nombreux contextes dâ€™apprentissage profond (traduction automatique, reÌsumeÌ de texte, traitement de seÌquences)
les modeÌ€les doivent manipuler des entreÌes de taille variable et se concentrer sur certaines parties plus que dâ€™autres.
Le meÌcanisme dâ€attention permet justement de donner plus de poids aÌ€ certains eÌleÌments dâ€™une seÌquence lors du calcul
dâ€™une sortie, en fonction de leur pertinence.
8.1 Motivation
ConsideÌrons la phrase suivante :
Â« An apple that had been on the tree in the garden for weeks had finally been picked up. Â»
qui en franÃ§ais pourrait se traduire par :
Â« Une pomme qui Ã©tait sur lâ€™arbre du jardin depuis des semaines avait finalement Ã©tÃ© ramassÃ©e. Â»
Ici, pour bien orthographier le mot ramassÃ©e, il faut avoir conscience quâ€™il fait reÌfeÌrence au nom une pomme qui est
feÌminin.
Pour quâ€™un modeÌ€le de traduction automatique soit capable dâ€™orthographier correctement ce mot, il faut donc quâ€™il soit
capable de modeÌliser des dÃ©pendances Ã  longue portÃ©e entre les mots.
Or, les architectures rÃ©currentes ou convolutives classiques ont du mal aÌ€ geÌrer efficacement ces deÌpendances aÌ€ cause :
â€” du goulot dâ€™Ã©tranglement (bottleneck) dans les repreÌsentations,
â€” de la difficulteÌ aÌ€ meÌmoriser des informations eÌloigneÌes.
Lâ€™attention reÌpond aÌ€ cette limite en permettant au modeÌ€le de se focaliser dynamiquement sur certaines entreÌes au mo-
ment de produire une sortie.
47


Introduction au Deep Learning (notes de cours)
8.2 Principe gÃ©nÃ©ral
Au lieu de reÌsumer lâ€™entreÌe par un seul vecteur fixe, comme dans les encodeurs reÌcurrents classiques, lâ€™attention geÌneÌ€re
une sortie en pondÃ©rant les diffÃ©rentes parties de lâ€™entrÃ©e selon leur pertinence.
Pour chaque eÌleÌment de la sortie, le modeÌ€le effectue une agrÃ©gation pondÃ©rÃ©e des eÌleÌments dâ€™entreÌe, ouÌ€ les poids refleÌ€tent
leur importance.
8.3 MÃ©taphore : Queries, Keys, Values
Lâ€™attention peut eÌ‚tre interpreÌteÌe via la meÌtaphore suivante :
â€” Query (Q) : ce que lâ€™on cherche
â€” Key (K) : ce que lâ€™on a comme reÌfeÌrence
â€” Value (V) : ce que lâ€™on extrait
On peut rapprocher ce meÌcanisme de ce qui se passe lorquâ€™on manipule un dictionnaire Python : dans un dictionnaire,
on cherche une cleÌ exacte pour obtenir la valeur associeÌe. Ici, la requeÌ‚te joue le roÌ‚le de la cleÌ rechercheÌe, mais au lieu
dâ€™une correspondance exacte, on compare la requeÌ‚te aÌ€ toutes les cleÌs disponibles (qui sont des vecteurs numeÌriques) en
mesurant leur similariteÌ (typiquement via un produit scalaire).
PlutoÌ‚t que de reÌcupeÌrer la valeur dâ€™une seule cleÌ, on effectue une moyenne pondÃ©rÃ©e des valeurs associeÌes aux cleÌs les
plus similaires aÌ€ la requeÌ‚te. Les poids de cette moyenne sont justement les similariteÌs calculeÌes entre la requeÌ‚te et chaque
cleÌ.
8.4 Formulation mathÃ©matique
Soient deux seÌquences de vecteurs dâ€™entreÌe ğ‘‹= [ğ‘¥1, â€¦ , ğ‘¥ğ‘›] et ğ‘Œ= [ğ‘¦1, â€¦ , ğ‘¦ğ‘š]. Lâ€™attention consiste aÌ€ projeter ğ‘‹en
requeÌ‚tes ğ‘„et ğ‘Œen cleÌs ğ¾et valeurs ğ‘‰:
ğ‘„= ğ‘‹ğ‘Šğ‘„
ğ¾= ğ‘Œğ‘Šğ¾
ğ‘‰= ğ‘Œğ‘Šğ‘‰
ouÌ€ ğ‘Šğ‘„, ğ‘Šğ¾, ğ‘Šğ‘‰sont des matrices de poids apprises.
Lâ€™attention est alors deÌfinie par :
Attention(ğ‘„, ğ¾, ğ‘‰) = softmax (ğ‘„ğ¾ğ‘‡
âˆšğ‘‘ğ‘˜
) ğ‘‰
ouÌ€ ğ‘‘ğ‘˜est la dimension des vecteurs cleÌs (utiliseÌ pour stabiliser lâ€™entraÃ®nement).
import torch
import numpy as np
import torch.nn.functional as F
torch.manual_seed(0)
Q = torch.randn(1, 4, 8)
# batch, longueur, dim
K = torch.randn(1, 6, 8)
# les clÃ©s ne sont pas forcÃ©ment de la mÃªme longueur
V = torch.randn(1, 6, 10) # la longueur des valeurs est celle des clÃ©s, leur dim peutâ£
(suite sur la page suivante)
48
Chapitre 8. MÃ©canisme dâ€™attention


Introduction au Deep Learning (notes de cours)
(suite de la page preÌceÌdente)
â†ªÃªtre autre
scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(8)
weights = F.softmax(scores, dim=-1)
output = torch.matmul(weights, V)
output.shape
# (1, 4, 10)
torch.Size([1, 4, 10])
8.5 Auto-attention (ou self-attention)
Dans certains cas, comme en traitement de seÌquence, les entreÌes ğ‘‹et ğ‘Œne sont quâ€™une seule et meÌ‚me seÌquence (on
souhaite comparer les eÌleÌments de la seÌquence deux aÌ€ deux) : on parle alors de self-attention.
Cela signifie que chaque position de la seÌquence ğ‘‹Â« regarde Â» toutes les autres positions de cette meÌ‚me seÌquence pour
construire sa propre repreÌsentation.
8.6 Multi-head attention
En pratique, dans la plupart des modeÌ€les, le meÌcanisme dâ€™attention est dupliqueÌ plusieurs fois (avec des poids diffeÌrents)
et leurs sorties sont concateÌneÌes : on parle alors de multi-head attention. Cela permet, dâ€™une part, aÌ€ chaque head de se
focaliser sur des aspects diffeÌrents de la seÌquence (syntaxe, structure, position, etc.). Au final, cela permet une modeÌlisation
plus riche des deÌpendances.
8.7 SchÃ©ma gÃ©nÃ©ral
8.8 RÃ©sumÃ©
â€” Le meÌcanisme dâ€™attention permet de capturer les deÌpendances entre eÌleÌments dâ€™une seÌquence sans contrainte de
distance.
â€” Il repose sur le calcul de similariteÌ entre requeÌ‚tes et cleÌs, et la pondeÌration des valeurs associeÌes.
â€” Il est aÌ€ la base des modeÌ€les Transformer, aujourdâ€™hui omnipreÌsents en NLP et en vision.
8.5. Auto-attention (ou self-attention)
49


Introduction au Deep Learning (notes de cours)
FĞ†ÔŒ. 8.1 â€“ ScheÌma dâ€™un bloc Transformer avec multi-head attention (source : HuggingFace).
50
Chapitre 8. MÃ©canisme dâ€™attention


CHAPITRE 9
REÌSEAUX NEURONAUX GEÌNEÌRATIFS
Les modeÌ€les geÌneÌratifs ont pour objectif dâ€™apprendre la distribution des donneÌes dâ€™entraÃ®nement. Cette distribution peut
eÌ‚tre estimeÌe de faÃ§on explicite, en apprenant une forme parameÌtrique de ğ‘(ğ‘¥) ou de la probabiliteÌ conditionnelle ğ‘(ğ‘¥|ğ‘¦),
ou bien approcheÌe de manieÌ€re implicite, sans forme close mais en permettant lâ€™eÌchantillonnage de nouvelles donneÌes.
Parmi les principaux modeÌ€les geÌneÌratifs, on retrouve les modeÌ€les de meÌlange gaussiens (GMM), les auto-encodeurs
variationnels (VAE), les reÌseaux adversaires geÌneÌratifs (GAN) et les modeÌ€les de diffusion. Chacun de ces modeÌ€les propose
une approche diffeÌrente pour modeÌliser et geÌneÌrer des donneÌes, allant de lâ€™estimation directe de la distribution aÌ€ des
meÌthodes plus indirectes baseÌes sur lâ€™eÌchantillonnage ou la compeÌtition entre reÌseaux.
9.1 Auto-encodeurs
Les auto-encodeurs [Hinton and Salakhutdinov, 2006] sont des reÌseaux qui apprennent aÌ€ compresser lâ€™information dans
un espace latent. Un auto-encodeur est constitueÌ dâ€™un bloc Encodeur et dâ€™un Bloc DeÌcodeur, utiliseÌs comme suit :
ğ‘§=Encodeur(ğ‘¥)
(9.1)
Ì‚ğ‘¥=Decodeur(ğ‘§)
(9.2)
Autrement dit, un encodeur projette lâ€™entreÌe ğ‘¥vers une repreÌsentation latente ğ‘§, geÌneÌralement de plus faible dimension,
puis un deÌcodeur reconstruit une approximation Ì‚ğ‘¥aÌ€ partir de ğ‘§. Ce fonctionnement peut eÌ‚tre vu comme une geÌneÌralisation
de lâ€™ACP au cas non lineÌaire. Toutefois, un auto-encodeur standard nâ€™est pas un modeÌ€le geÌneÌratif, car il nâ€™impose pas de
distribution particulieÌ€re sur lâ€™espace latent ğ‘§et nâ€™offre donc pas de faÃ§on de tirer de nouveaux samples.
51


Introduction au Deep Learning (notes de cours)
9.2 Variational Auto-Encoders (VAE)
Les VAE [Kingma and Welling, 2014] transforment lâ€™auto-encodeur en modeÌ€le geÌneÌratif en imposant un a priori sur la
variable latente ğ‘§, typiquement une loi normale ğ‘§âˆ¼ğ’©(0, ğ¼). Une peÌnalisation, sous forme de divergence de Kullback-
Leibler (KL), est ajouteÌe aÌ€ la fonction de perte aÌ€ optimiser pour encourager la distribution latente aÌ€ respecter cet a priori.
Pour geÌneÌrer de nouvelles donneÌes :
1. on tire un ğ‘§selon ğ’©(0, ğ¼)
2. on calcule ğ‘¥gen = Decodeur(ğ‘¥)
9.3 Generative Adversarial Networks (GAN)
ProposeÌs par [Goodfellow et al., 2014], les GAN entraÃ®nent deux reÌseaux :
â€” un GeÌneÌrateur ğºqui produit ğ‘¥fake = ğº(ğ‘§) aÌ€ partir de bruit ğ‘§âˆ¼ğ’©(0, ğ¼)
â€” un Discriminateur ğ·qui preÌdit si une entreÌe ğ‘¥est reÌelle (ğ‘¦= 1) ou geÌneÌreÌe (ğ‘¦= 0)
La fonction de perte optimiseÌe est la suivante :
ğ”¼ğ‘¥âˆ¼ğ‘ğ‘Ÿ[log ğ·(ğ‘¥)] + ğ”¼ğ‘§âˆ¼ğ‘ğ‘§[log(1 âˆ’ğ·(ğº(ğ‘§)))]
(9.3)
ConcreÌ€tement, lâ€™entraÃ®nement alterne entre mise aÌ€ jour de ğ·(meilleure discrimination, maximisation de la fonction de
perte) et mise aÌ€ jour de ğº(meilleure geÌneÌration, minimisation de la fonction de perte).
Pour la geÌneÌration, comme pour un VAE, on tire un ğ‘§âˆ¼ğ’©(0, ğ¼) puis on le fournit en entreÌe au geÌneÌrateur pour geÌneÌrer
un nouveau sample ğº(ğ‘§).
En pratique, lâ€™optimisation dâ€™un GAN est souvent instable, et il est souvent neÌcessaire dâ€™utiliser des astuces pour le stabiliser
(cf les Wasserstein GAN par exemple [Arjovsky et al., 2017]).
9.4 ModÃ¨les de diffusion
Les modeÌ€les de diffusion, introduits par [Ho et al., 2020], reposent sur une ideÌe originale : on ajoute progressivement du
bruit gaussien aux donneÌes, puis on entraÃ®ne un modeÌ€le aÌ€ inverser ce processus, câ€™est-aÌ€-dire aÌ€ deÌbruiter les donneÌes eÌtape
par eÌtape. Lors de la geÌneÌration, on part dâ€™un bruit pur et on le transforme progressivement en une donneÌe reÌaliste.
9.5 Conditional Flow Matching
Le Conditional Flow Matching, proposeÌ par [Lipman et al., 2023], consiste aÌ€ apprendre un champ de vecteurs qui trans-
porte progressivement les eÌchantillons du bruit (eÌtat initial ğ‘¡= 0, correspondant au ğ‘§introduit plus haut pour les VAE et
les GAN) vers les donneÌes reÌelles (eÌtat final ğ‘¡= 1, correspodant au ğ‘¥plus haut). Lâ€™entraÃ®nement repose sur la minimisation
de la fonction de perte suivante :
ğ”¼ğ‘¥0,ğ‘¥1,ğ‘¡[ğ‘¢ğœƒ(ğ‘¥, ğ‘¡) âˆ’(ğ‘¥1 âˆ’ğ‘¥0)]
(9.4)
ouÌ€ ğ‘¥= ğ‘¡ğ‘¥0 + (1 âˆ’ğ‘¡)ğ‘¥1.
Une fois le modeÌ€le ğ‘¢ğœƒappris, la geÌneÌration sâ€™effectue en reÌsolvant une eÌquation diffeÌrentielle, par exemple avec le scheÌma
dâ€™Euler, en partant dâ€™un sample ğ‘¥0 tireÌ de ğ’©(0, ğ¼) :
ğ‘¥ğ‘¡+ğœ€â†ğ‘¥ğ‘¡+ ğœ€ğ‘¢ğœƒ(ğ‘¥ğ‘¡, ğ‘¡)
(9.5)
Ce processus peut eÌ‚tre vu comme une interpolation guideÌe entre le bruit et les donneÌes.
52
Chapitre 9. RÃ©seaux neuronaux gÃ©nÃ©ratifs


Introduction au Deep Learning (notes de cours)
9.6 RÃ©sumÃ©
En reÌsumeÌ, les modeÌ€les geÌneÌratifs offrent des outils puissants pour modeÌliser et eÌchantillonner la distribution des don-
neÌes. Selon lâ€™approche choisie, ils peuvent consister aÌ€ compresser lâ€™information en imposant une structure probabiliste sur
lâ€™espace latent (VAE), aÌ€ geÌneÌrer des donneÌes par compeÌtition entre reÌseaux (GAN), ou encore aÌ€ produire des eÌchantillons
via des processus dynamiques et progressifs (diffusion et flow matching).
9.6. RÃ©sumÃ©
53


Introduction au Deep Learning (notes de cours)
54
Chapitre 9. RÃ©seaux neuronaux gÃ©nÃ©ratifs


BIBLIOGRAPHIE
[Goh17]
Gabriel Goh. Why momentum really works. Distill, 2017. URL: http://distill.pub/2017/momentum.
[KB15]
Diederik P. Kingma and Jimmy Ba. Adam: a method for stochastic optimization. In Yoshua Bengio and
Yann LeCun, editors, ICLR. 2015.
[SHK+14]
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dro-
pout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research,
15(56):1929â€“1958, 2014. URL: http://jmlr.org/papers/v15/srivastava14a.html.
[FFW+19]
Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and Pierre-Alain Muller.
Deep learning for time series classification: a review. Data Mining and Knowledge Discovery, 33(4):917â€“
963, 2019.
[FLF+20]
Hassan Ismail Fawaz, Benjamin Lucas, Germain Forestier, Charlotte Pelletier, Daniel F Schmidt, Jonathan
Weber, Geoffrey I Webb, Lhassane Idoumghar, Pierre-Alain Muller, and FranÃ§ois Petitjean. Inception-
time: finding alexnet for time series classification. Data Mining and Knowledge Discovery, 34(6):1936â€“1962,
2020.
[LGMT16] Arthur Le Guennec, Simon Malinowski, and Romain Tavenard. Data Augmentation for Time Series Clas-
sification using Convolutional Neural Networks. In ECML/PKDD Workshop on Advanced Analytics and
Learning on Temporal Data. Riva Del Garda, Italy, September 2016.
[LBBH98]
Yann LeCun, LeÌon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to docu-
ment recognition. Proceedings of the IEEE, 86(11):2278â€“2324, 1998.
[CVMerrienboerBB14] Kyunghyun Cho, Bart Van MerrieÌˆnboer, Dzmitry Bahdanau, and Yoshua Bengio. On the pro-
perties of neural machine translation: encoder-decoder approaches. 2014. arXiv:1409.1259.
[HS97]
Sepp Hochreiter and JuÌˆrgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735â€“1780,
1997.
[Mad19]
Andreas Madsen. Visualizing memorization in rnns. Distill, 2019. URL: https://distill.pub/2019/
memorization-in-rnns.
[ACB17]
Martin Arjovsky, Soumith Chintala, and LeÌon Bottou. Wasserstein generative adversarial networks. In Pro-
ceedings of the International Conference on Machine Learning, 214â€“223. PMLR, 2017.
[GPAM+14] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. Generative adversarial nets. In Neural Information Processing Systems. 2014.
[HS06]
Geoffrey E Hinton and Ruslan R Salakhutdinov. Reducing the dimensionality of data with neural networks.
Science, 313(5786):504â€“507, 2006.
[HJA20]
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In Neural Information
Processing Systems. 2020.
[KW14]
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114,
2014.
55


Introduction au Deep Learning (notes de cours)
[LCBH+23] Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le. Flow matching for
generative modeling. In Proceedings of the International Conference on Learning Representations. 2023.
56
Bibliographie
